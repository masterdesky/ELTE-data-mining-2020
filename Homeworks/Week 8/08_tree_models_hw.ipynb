{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision tree based models\n",
    "\n",
    "This week we will use the https://archive.ics.uci.edu/ml/datasets/Early+stage+diabetes+risk+prediction+dataset.# diabetes dataset. Our goal is to classify people based on their symptoms if they have diabetes or not.\n",
    "\n",
    "#### 1. Prepare dataset\n",
    " - load the diabetes_data_upload.csv dataset\n",
    " - search for missing values and if needed, handle them!\n",
    " - encode the non numeric variables into numeric ones! For the binary features simply encode them as (0/1), do not create two separate columns for them!\n",
    "\n",
    "#### 2. Train & visualize decision tree classifier\n",
    " - train a decision tree classifier using the sklearn API\n",
    " - use its default parameters\n",
    " - for training use all the data, this is only and exploratory task now\n",
    " - visualize the decision tree (the `plot_tree` function in sklearn will be helpful)\n",
    " - manually check for two cases if the returned Gini impurities are correct\n",
    " - in a few sentences discuss the results\n",
    "\n",
    "#### 3.  Random forest feature importance\n",
    " - train a random forest classifier on all the data using the sklearn API\n",
    " - use default values again, but fix the random_state to 42!\n",
    " - plot the 10 most important features' importances\n",
    "    - create a bar plot where the height of the bar is the feature importance\n",
    "    - show the 10 features where the feature importance is the highest\n",
    "    - `feature_importance` attribute is helpful\n",
    "\n",
    "#### 4. Evaluation\n",
    " - generate prediction probabilities with a decision tree and with a random forest model\n",
    " - use 5 fold cross validation for both time (so you should get 520 predictions)\n",
    " - use default parameters for both models\n",
    " - compare the two models with ROC curves\n",
    "   - why does the decision tree's ROC curve looks different?\n",
    " \n",
    "#### 5. Tuning model\n",
    "  - using 80/20% train/test split generate predictions for a random forest model\n",
    "  - plot the AUC vs number of trees in the forest for both the traing and the test data\n",
    "  - do we experience overfitting if we use too many trees?\n",
    "\n",
    "\n",
    "### Hints:\n",
    " - On total you can get 10 points for fully completing all tasks.\n",
    " - Decorate your notebook with, questions, explanation etc, make it self contained and understandable!\n",
    " - Comments you code when necessary\n",
    " - Write functions for repetitive tasks!\n",
    " - Use the pandas package for data loading and handling\n",
    " - Use matplotlib and seaborn for plotting or bokeh and plotly for interactive investigation\n",
    " - Use the scikit learn package for almost everything\n",
    " - Use for loops only if it is really necessary!\n",
    " - Code sharing is not allowed between student! Sharing code will result in zero points.\n",
    " - If you use code found on web, it is OK, but, make its source clear! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
