{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please work on Google Colab.\n",
    "\n",
    "### 1. Load the MNIST dataset and create a CNN model\n",
    "\n",
    "- load the MNIST dataset from the tensorflow/keras built-in dataset (just like last time)\n",
    "- use the original train/test split!\n",
    "- divide each pixel's value by 255 and now do not reshape, leave it as is (2D matrix (28x28) )\n",
    "- eg for the test set you will have a (10000, 28, 28) shaped vector\n",
    "- train the following network on the training set and generate prediction for the 10.000 test images:\n",
    "\n",
    "        input (28, 28)\n",
    "        conv2D, 16 kernels, kernel size = 3, valid padding, relu activation\n",
    "        conv2D, 16 kernels, kernel size = 3, valid padding, relu activation\n",
    "        maxpooling kernel size = 2*2\n",
    "        conv2D, 32 kernels, kernel size = 3, valid padding, relu activation\n",
    "        conv2D, 32 kernels, kernel size = 3, valid padding, relu activation\n",
    "        maxpooling kernel size = 2*2\n",
    "        flatten\n",
    "        dense, 10 neurons, softmax activation\n",
    "    * pay attention to channel format, you will need to expand dims!\n",
    "    * how many parameters do we have for each layer?\n",
    "    * use Adam optimizer with default parameters\n",
    "    * use categorical crossentropy as loss function\n",
    "    * compile the model\n",
    "    * print out a summary of the model\n",
    "    * train the CNN on the training data for 5 epochs with batch size of 32\n",
    "    * use the test data as validation data\n",
    "        \n",
    "- calculate the categorical cross-entropy loss and the accuracy! Hint: you should get at least ~98% accuracy\n",
    "- show the confusion matrix of the predictions (predicted values vs actual labels)\n",
    "- where does the model make mistakes? Where does it improve compared to fully connected nets?\n",
    "\n",
    "### 2. Download the Street View House Numbers (SVHN) Dataset\n",
    "\n",
    "- source: http://ufldl.stanford.edu/housenumbers/\n",
    "- use the cropped dataset!\n",
    "- to get the dataset use eg. wget and keep the original splitting, so download train and test matrix files\n",
    "- preprocess the downloaded data to be able to use it for training and testing, so shapes should be same (except image sizes) as it was in ex 1.\n",
    "- how many classes do we have in the dataset? how many train and test examples do we have?\n",
    "- what is the dimension of the images?\n",
    "- show 5 images from the dataset\n",
    "- make one-hot encoding for the labels\n",
    "\n",
    "### 3. Train the CNN model seen in the 1st exercise for this dataset\n",
    "* create a convolutional neural network\n",
    "* the network should have the following layers:\n",
    "        \n",
    "        input (32, 32, 3)\n",
    "        conv2D, 16 kernels, kernel size = 3, valid padding, relu actvation\n",
    "        conv2D, 16 kernels, kernel size = 3, valid padding, relu actvation\n",
    "        maxpooling kernel size = 2*2\n",
    "        conv2D, 32 kernels, kernel size = 3, valid padding, relu actvation\n",
    "        conv2D, 32 kernels, kernel size = 3, valid padding, relu actvation\n",
    "        maxpooling kernel size = 2*2\n",
    "        flatten\n",
    "        dense, 10 neurons, softmax activation\n",
    "        how many parameters do we have for each layer?\n",
    "\n",
    "    * use Adam optimizer with default parameters\n",
    "    * use categorical crossentropy as loss function\n",
    "    * compile the model\n",
    "    * print out a summary of the model\n",
    "    * train the CNN on the training data for 15 epochs with batch size of 32\n",
    "    * use the test data as validation data\n",
    "- calculate the categorical cross-entropy loss and the accuracy! Hint: you should get at least ~80-90% accuracy\n",
    "\n",
    "### 4. Evaluate performance\n",
    "\n",
    "- plot the training and the validation loss on the same plot!\n",
    "- plot the training and the validation accuracy on the same plot!\n",
    "- do we overfit?\n",
    "- show the confusion matrix of the predictions (predicted values vs actual labels)\n",
    "- where does the model make mistakes?\n",
    "\n",
    "### 5. Train an other CNN\n",
    "- as we can see the previous architecture can be further improved\n",
    "- come up with an architecture that can achieve more than 91% accuracy on the test set\n",
    "- print out the summary for this model!\n",
    "- plot the loss and accuracy curves for this model too!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
