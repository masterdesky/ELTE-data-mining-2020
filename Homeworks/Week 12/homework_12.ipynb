{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Last homework\n",
    "\n",
    "This week we will apply techniques learned during the semester as a recap of the learned methods. We will use a dataset from the paper \"Hurricane-induced selection on the morphology of an island lizard\", where body parameters of lizards are measured on an island before and after the hurricane. We will make binary predictions if a lizard was measured before of after the hurricane in the upcoming tasks.\n",
    "\n",
    "When a task is not fully described, try to come up with a reasonable solution!\n",
    "\n",
    "Data source: https://www.nature.com/articles/s41586-018-0352-3#Sec7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as plticker\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hw_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = './data/'\n",
    "out = './out/'\n",
    "\n",
    "# Bold print for Jupyter Notebook\n",
    "b1 = '\\033[1m'\n",
    "b0 = '\\033[0m'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Just some matplotlib and seaborn parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axistitlesize = 20\n",
    "axisticksize = 17\n",
    "axislabelsize = 26\n",
    "axislegendsize = 23\n",
    "axistextsize = 20\n",
    "axiscbarfontsize = 15\n",
    "\n",
    "# Set axtick dimensions\n",
    "major_size = 6\n",
    "major_width = 1.2\n",
    "minor_size = 3\n",
    "minor_width = 1\n",
    "mpl.rcParams['xtick.major.size'] = major_size\n",
    "mpl.rcParams['xtick.major.width'] = major_width\n",
    "mpl.rcParams['xtick.minor.size'] = minor_size\n",
    "mpl.rcParams['xtick.minor.width'] = minor_width\n",
    "mpl.rcParams['ytick.major.size'] = major_size\n",
    "mpl.rcParams['ytick.major.width'] = major_width\n",
    "mpl.rcParams['ytick.minor.size'] = minor_size\n",
    "mpl.rcParams['ytick.minor.width'] = minor_width\n",
    "\n",
    "mpl.rcParams.update({'figure.autolayout': False})\n",
    "\n",
    "# Seaborn style settings\n",
    "sns.set_style({'axes.axisbelow': True,\n",
    "               'axes.edgecolor': '.8',\n",
    "               'axes.facecolor': 'white',\n",
    "               'axes.grid': True,\n",
    "               'axes.labelcolor': '.15',\n",
    "               'axes.spines.bottom': True,\n",
    "               'axes.spines.left': True,\n",
    "               'axes.spines.right': True,\n",
    "               'axes.spines.top': True,\n",
    "               'figure.facecolor': 'white',\n",
    "               'font.family': ['sans-serif'],\n",
    "               'font.sans-serif': ['Arial',\n",
    "                'DejaVu Sans',\n",
    "                'Liberation Sans',\n",
    "                'Bitstream Vera Sans',\n",
    "                'sans-serif'],\n",
    "               'grid.color': '.8',\n",
    "               'grid.linestyle': '--',\n",
    "               'image.cmap': 'rocket',\n",
    "               'lines.solid_capstyle': 'round',\n",
    "               'patch.edgecolor': 'w',\n",
    "               'patch.force_edgecolor': True,\n",
    "               'text.color': '.15',\n",
    "               'xtick.bottom': True,\n",
    "               'xtick.color': '.15',\n",
    "               'xtick.direction': 'in',\n",
    "               'xtick.top': True,\n",
    "               'ytick.color': '.15',\n",
    "               'ytick.direction': 'in',\n",
    "               'ytick.left': True,\n",
    "               'ytick.right': True})\n",
    "\n",
    "# Colorpalettes, colormaps, etc.\n",
    "sns.set_palette(palette='rocket')\n",
    "rocket_cmap = sns.color_palette('rocket', as_cmap=True)\n",
    "\n",
    "target_colors = np.array([cm.magma(0.5), cm.magma(0.75), cm.magma(0.93)])\n",
    "feature_colors = np.array([rocket_cmap(0.17), cm.magma(0.45), cm.magma(0.60), cm.magma(0.75)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load & prepare data\n",
    " - load the provided dataset\n",
    " - look for missing values, handle them! Be careful! (You can screw up the whole assignment here)\n",
    " - We will make binary predictions if a lizard was before of after the hurricane in the upcoming tasks. \n",
    " - Convert all the features to numeric or binary features.\n",
    " - get rid of the ID column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1./a. Load and explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = os.listdir(data)[0]\n",
    "df = pd.read_csv(data + f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.head())\n",
    "display(df.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select binary and non-binary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cut off the ID column\n",
    "columns = df.columns.delete([0])\n",
    "\n",
    "# Column types:\n",
    "# Binary columns     : columns[:3]\n",
    "# Non-binary columns : columns[3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Binary feature values:\\n'+\n",
    "      '======================')\n",
    "print('`Origin`:', np.unique(df['Origin']))\n",
    "print('`Hurricane`:', np.unique(df['Hurricane']))\n",
    "print('`Sex`:', np.unique(df['Sex']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert binary columns from string values to ints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy original DataFrame to keep it intact\n",
    "df_n = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a map for binary values and apply it on the copied DataFrame\n",
    "map_origin = {'Pine Cay' : 0, 'Water Cay' : 1}\n",
    "map_hurricane = {'Before' : 0, 'After' : 1}\n",
    "map_sex = {'Female' : 0, 'Male' : 1}\n",
    "\n",
    "df_n['Origin'] = df['Origin'].map(map_origin)\n",
    "df_n['Hurricane'] = df['Hurricane'].map(map_hurricane)\n",
    "df_n['Sex'] = df['Sex'].map(map_sex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1./b. Explore NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mask to analyze missing entries easier\n",
    "nan_mask = df_n.isna()\n",
    "nan_count = nan_mask.sum()\n",
    "print('Count of missing values:\\n' +\n",
    "      '========================')\n",
    "print(tabulate([[c, nan_count[c]] for c in nan_count.index], headers=['Feature', 'Count of NaNs']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a dataframe to mark NaN values\n",
    "df_nan = np.array(df_n[columns].isna()).T\n",
    "\n",
    "## Create a mask for hurricane entries\n",
    "# Get indeces of hurricane\n",
    "mask = (df_n['Hurricane'] == 1)\n",
    "inds = np.array(mask[mask.values].index)\n",
    "# Create mask to mark rows with Hurricane == 1 values as 1s\n",
    "df_mask = np.zeros_like(df_nan).astype(int)\n",
    "df_mask.T[inds] = np.ones((inds.size, columns.size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize=(20,20))\n",
    "axes.set_aspect('equal')\n",
    "\n",
    "axes.imshow(np.array(df_n[columns].isna()).T)\n",
    "axes.imshow(df_mask, cmap=cm.seismic, alpha=0.4)\n",
    "\n",
    "# Remove XY ticks for now\n",
    "axes.set_xticks([])\n",
    "axes.set_yticks([])\n",
    "\n",
    "# Lapelpad needed because of the removed ticks\n",
    "lp = 20\n",
    "axes.set_xlabel('Rows', fontsize=axislabelsize, fontweight='bold', labelpad=lp)\n",
    "axes.set_ylabel('Columns', fontsize=axislabelsize, fontweight='bold', labelpad=lp)\n",
    "\n",
    "plt.suptitle('Fig. 1. Missing entries in the original dataset. Rows of pre-hurricane measurements\\n' +\n",
    "             'are colored with a blue-ish color, while post-hurricane measurements have a red-colored overlay.',\n",
    "             fontsize=axistitlesize+2, y=0.4)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1./c. Inspect distribution of non-binary values before and after the hurricane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'a' and 'b' indicates the before and after hurricane measurements\n",
    "hist = {'b': {}, 'a': {}}\n",
    "bins = {'b': {}, 'a': {}}\n",
    "width = {'b': {}, 'a': {}}\n",
    "center = {'b': {}, 'a': {}}\n",
    "\n",
    "#\n",
    "# THROWS RuntimeWarning, because some pre-hurricane values are completely missing from the dataset.\n",
    "# Can be fully ignored here.\n",
    "#\n",
    "for t in ['b', 'a']:\n",
    "    df_cut = df_n[~mask] if t=='b' else df_n[mask]\n",
    "    for c in columns[3:]:\n",
    "        hist[t][c], bins[t][c] = np.histogram(df_cut[c][~df_cut[c].isna()], bins=10, density=True)\n",
    "        width[t][c] = 0.8 * (bins[t][c][1] - bins[t][c][0])\n",
    "        center[t][c] = (bins[t][c][:-1] + bins[t][c][1:]) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncols = 5\n",
    "nrows = (columns[3:].size+ncols-1)//ncols\n",
    "fig, axes = plt.subplots(nrows, ncols, figsize=(ncols*4, nrows*4))\n",
    "\n",
    "colors = [cm.magma(0.45), cm.magma(0.85)]\n",
    "labels = ['Pre-hurricane', 'Post-hurricane']\n",
    "# Loop through axes/features\n",
    "for col_i, ax in enumerate(axes.reshape(-1)):\n",
    "    # Turn off all surplus axes\n",
    "    if col_i < columns[3:].size:\n",
    "        col = columns[3:][col_i]\n",
    "        # Loop through the two before-after datasets\n",
    "        # ('t' here supposed to mean \"time\")\n",
    "        for t_i, t in enumerate(['b', 'a']):\n",
    "            ax.bar(center[t][col], hist[t][col], width=width[t][col],\n",
    "                   label=labels[t_i],\n",
    "                   color=colors[t_i], alpha=0.7,\n",
    "                   ec='black', lw=0.5, align='center')\n",
    "            ax.set_title(col, fontsize=axistitlesize-5, fontweight='bold')\n",
    "            ax.set_ylabel('')\n",
    "            \n",
    "            ax.legend(loc='upper right')\n",
    "\n",
    "    else : ax.axis('off')\n",
    "plt.suptitle('Fig. 2. Distribution of non-binary labels in the original dataset.',\n",
    "             fontsize=axistitlesize+5, y=0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1./d. Actually handling missing values\n",
    "\n",
    "The columns from `FingerCount` to `MeanToeArea` misses only one value in each column. The image above shows, that these values are all missing from the same row, thus we might want to consider removing it from the dataset. The real problem is caused by the columns `SumFingers`, `SumToes` and `MaxFingerForce`, which is probably referred to as \"you can screw up the whole assignment here trollolo\" in the task description.\n",
    "\n",
    "We're basically studying here that what characteristics do those reptiles have, which survives/get through the event of a hurricane. These reptiles will be maybe the stronger/more viable types, which can grip onto something for a longer time and with more force and stability - to stand against the winds in the hurricane. It could happen, that much smaller lizards with less grip force have higher survival rate, since they can hide easier than bigger (and thus stronger) animals. Also the distribution of these features can easily differ before and after the hurricane, since animals are probably much more tired, etc. We'll see the truth soon...\n",
    "\n",
    "The problem is, that at the end of the day, the `SumFingers`, `SumToes` and `MaxFingerForce` features will probably have big impact on the model and we have to consider to keep them at any cost. Figure 1. and Figure 2. shows however, that we have literally no measurements about them before the hurricane. In contrast of everything I've written in the last two paragraphs, this indicates us that we probably should drop these features from the dataset. I really do hope, I won't screw up the dataset with this..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Address the rows and features with lot of missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check number of missing elements in rows\n",
    "print('Missing number of values per rows:\\n' +\n",
    "      '==================================')\n",
    "df_miss_r = np.array(df_n.isna()).sum(axis=1)\n",
    "print(df_miss_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check number of missing elements in rows\n",
    "print('Missing number of values per columns:\\n' +\n",
    "      '==================================')\n",
    "df_miss_c = np.array(df_n.isna()).sum(axis=0)\n",
    "print(df_miss_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the row with lot of missing values\n",
    "df_fin = df_n.drop(labels=[\n",
    "                    np.where(\n",
    "                        df_miss_r == df_miss_r.max()\n",
    "                    )[0][0]\n",
    "                ])\n",
    "# Fill back created hole in indeces\n",
    "df_fin.index = pd.Int64Index(np.arange(0,len(df_fin)))\n",
    "\n",
    "# Remove features with lot of missing values\n",
    "df_fin = df_fin.drop(columns=['SumFingers', 'SumToes', 'MaxFingerForce'])\n",
    "\n",
    "# Final set of features\n",
    "# (Cut ID columns)\n",
    "features = df_fin.columns[1:]\n",
    "df_fin = df_fin[features]\n",
    "print('Final set of features:\\n' +\n",
    "      '======================')\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1./e. Check our dataset after the preprocession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a dataframe to mark NaN values\n",
    "df_nan = np.array(df_fin.isna()).T\n",
    "\n",
    "## Create a mask for hurricane entries\n",
    "# Get indeces of hurricane\n",
    "mask = (df_fin['Hurricane'] == 1)\n",
    "inds = np.array(mask[mask.values].index)\n",
    "# Create mask to mark rows with Hurricane == 1 values as 1s\n",
    "df_mask = np.zeros_like(df_nan).astype(int)\n",
    "df_mask.T[inds] = np.ones((inds.size, features.size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize=(20,20))\n",
    "axes.set_aspect('equal')\n",
    "\n",
    "axes.imshow(np.array(df_fin[features].isna()).T)\n",
    "axes.imshow(df_mask, cmap=cm.seismic, alpha=0.4)\n",
    "\n",
    "# Remove XY ticks for now\n",
    "axes.set_xticks([])\n",
    "axes.set_yticks([])\n",
    "\n",
    "# Lapelpad needed because of the removed ticks\n",
    "lp = 20\n",
    "axes.set_xlabel('Rows', fontsize=axislabelsize, fontweight='bold', labelpad=lp)\n",
    "axes.set_ylabel('Columns', fontsize=axislabelsize, fontweight='bold', labelpad=lp)\n",
    "\n",
    "plt.suptitle('Fig. 3. Missing entries in the preprocessed dataset. Rows of pre-hurricane measurements\\n' +\n",
    "             'are colored with a blue-ish color, while post-hurricane measurements have a red-colored overlay.\\n' +\n",
    "             'We can see, there are no NaN values present in the final dataset.',\n",
    "             fontsize=axistitlesize+2, y=0.4)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. T-SNE\n",
    " - embed the data points into a 2D space via T-SNE (preprocess the data if needed). For embedding, use only the numerical features (So do not use Sex, Hurricane and Origin features)\n",
    " - what is common in the clusters that we got? visualize the embedded points by using different colour for the different fetautre values (eg on a plot show the female gekkos with red and the male ones with blue). Explore at least 4 features! Do we get separation by the Hurricane variable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.lines import Line2D\n",
    "\n",
    "from sklearn import decomposition\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use only non-binary values\n",
    "df_tsne = df_fin[features[3:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Perform t-SNE in the scaled data with 2 components\n",
    "df_embedded_variation = []\n",
    "perplexity = [2, 5, 10, 30, 50, 100]\n",
    "for p in perplexity:\n",
    "    df_embedded_variation.append(TSNE(n_components=2, perplexity=p).fit_transform(df_tsne))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tsne(f_to_color='Sex',\n",
    "              fig_text=''):\n",
    "    \n",
    "    nrows = 2\n",
    "    ncols = 3\n",
    "    fig, axes = plt.subplots(nrows, ncols, figsize=(12*ncols, 12*nrows))\n",
    "\n",
    "    # scatter point radius\n",
    "    sc_rad = 9\n",
    "\n",
    "    # Set a colormap for scatter points\n",
    "    # Color points by a chosen binary feature\n",
    "    bin_colors = np.array(['tab:red', 'tab:blue'])\n",
    "    colors = bin_colors[(df_fin[f_to_color] == 1).astype(int)]\n",
    "    # Select labels for points\n",
    "    if f_to_color.lower() == 'sex': _map = map_sex\n",
    "    elif f_to_color.lower() == 'hurricane': _map = map_hurricane\n",
    "    elif f_to_color.lower() == 'origin': _map = map_origin\n",
    "    inv_map = {v: k for k, v in _map.items()}\n",
    "    labels = list(inv_map.values())\n",
    "\n",
    "    # Plot the t-SNE domains\n",
    "    for i in range(nrows):\n",
    "        for j in range(ncols):\n",
    "            ax = axes[i][j]\n",
    "            # Select embedding with the correct perplexity\n",
    "            df_embedded = df_embedded_variation[i*ncols + j]\n",
    "            x = df_embedded[:,0]\n",
    "            y = df_embedded[:,1]\n",
    "            ax.scatter(x, y,\n",
    "                       color=colors, s=sc_rad**2, alpha=0.7)\n",
    "\n",
    "            ax.set_title('Perplexity = {0}'.format(perplexity[i*ncols + j]), fontsize=axistitlesize, fontweight='bold')\n",
    "            ax.set_xlabel('Embedding dim. 1', fontsize=axislabelsize, fontweight='bold', labelpad=15)\n",
    "            ax.set_ylabel('Embedding dim. 2', fontsize=axislabelsize, fontweight='bold', labelpad=15)\n",
    "            ax.tick_params(axis='both', which='major', labelsize=axisticksize)\n",
    "\n",
    "            handles = [Line2D([0], [0], marker='o', color='w', label=labels[0],\n",
    "                              markerfacecolor=bin_colors[0], markersize=15),\n",
    "                       Line2D([0], [0], marker='o', color='w', label=labels[1],\n",
    "                              markerfacecolor=bin_colors[1], markersize=15)]\n",
    "            ax.legend(loc='best', handles=handles, fontsize=axislegendsize)\n",
    "\n",
    "    fig.suptitle(fig_text,\n",
    "                 fontsize=axistitlesize+12, y=0.04)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Coloring by `Sex`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_to_color = 'Sex'\n",
    "plot_tsne(f_to_color,\n",
    "          'Fig. 4. Embeddings of a t-SNE performed with two components.\\nReptiles are colored by the `{0}` feature.'.format(f_to_color))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Coloring by `Hurricane`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_to_color = 'Hurricane'\n",
    "plot_tsne(f_to_color,\n",
    "          'Fig. 5. Embeddings of a t-SNE performed with two components.\\nReptiles are colored by the `{0}` feature.'.format(f_to_color))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Coloring by `Origin`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_to_color = 'Origin'\n",
    "plot_tsne(f_to_color,\n",
    "          'Fig. 6. Embeddings of a t-SNE performed with two components.\\nReptiles are colored by the `{0}` feature.'.format(f_to_color))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3./b. Conclusions\n",
    "\n",
    "We get a clear separation for sexes for almost every perplexity values. However neither the feature `Origin` nor the target feature `Hurricane` shows any separation..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Linear model + fine-tune\n",
    " - train and generate predictions with a logistic regression model using 5 fold cross validation\n",
    " - fine-tune the regularization strength for L2 regularization type!\n",
    " - show the ROC curve with the AUC value for the best model that you have found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_fin[features[3:]]\n",
    "y = df_fin['Hurricane']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5-fold search is needed\n",
    "folds = 5\n",
    "cv = KFold(n_splits=folds, shuffle=True, random_state=42)\n",
    "# LogisticRegression model\n",
    "model = LogisticRegression(max_iter=1e05, random_state=42, n_jobs=-1)\n",
    "# Paramters to explored:\n",
    "# C : regularization strength\n",
    "param_grid = {\n",
    "    'C' : np.logspace(-10, 1, 100),\n",
    "}\n",
    "# Grid search cross-validation\n",
    "clf = GridSearchCV(estimator=model,\n",
    "                   param_grid=param_grid,\n",
    "                   cv=cv,\n",
    "                   n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "best_model = clf.fit(X_train, y_train).best_estimator_\n",
    "print('Best model : {0}'.format(best_model))\n",
    "y_pred = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and accuracy metric and the confusion matrix\n",
    "accuracy = accuracy_metric(y_test=y_test, y_pred=y_pred)\n",
    "conf_mat = confusion_matrix(y_test, y_pred, labels=[i for i in range(0,2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(conf_mat, y_test, labels=['Before', 'After'],\n",
    "                      title=('Fig. 7. Confusion matrix of the predictions\\n' +\n",
    "                             'on the test set using fine-tuned Logistic Regression.\\n' +\n",
    "                             'Accuracy of model is {0:.3f}%'.format(accuracy)),\n",
    "                     figsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_tr, tpr_tr, roc_auc_tr = compute_roc(best_model, X_train, y_train)\n",
    "fpr_ts, tpr_ts, roc_auc_ts = compute_roc(best_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize=(11, 11),\n",
    "                         facecolor='black', subplot_kw={'facecolor' : 'black'})\n",
    "\n",
    "axes.plot([0, 1], [0, 1], color=rocket_cmap(0.25), lw=5, linestyle='--')\n",
    "\n",
    "# My model\n",
    "axes.plot(fpr_tr, tpr_tr,\n",
    "          label='ROC curve [train] \\n(AUC = %0.3f)' % roc_auc_tr,\n",
    "          color=cm.magma(0.75), lw=4, alpha=0.8)\n",
    "axes.plot(fpr_ts, tpr_ts,\n",
    "          label='ROC curve [test] \\n(AUC = %0.3f)' % roc_auc_ts,\n",
    "          color=cm.magma(0.93), lw=4, alpha=0.8)\n",
    "\n",
    "axes.set_xlim([-0.02, 1.02])\n",
    "axes.set_ylim([-0.02, 1.02])\n",
    "\n",
    "axes.set_xlabel('False Positive Rate', fontsize=axislabelsize, fontweight='bold', color='white')\n",
    "axes.set_ylabel('True Positive Rate', fontsize=axislabelsize, fontweight='bold', color='white')\n",
    "axes.tick_params(axis='both', which='major', labelsize=axisticksize, colors='white')\n",
    "\n",
    "axes.legend(loc='lower right', fontsize=axislegendsize)\n",
    "\n",
    "plt.suptitle('Fig. 9. ROC curve of the fine-tuned LogisticRegression,\\n' +\n",
    "             'model on the lizard-hurricane dataset.',\n",
    "             fontsize=axistitlesize+5, y=0.04, color='white')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. SVM + fine-tune\n",
    " - train and generate predictions with an SVM model using 5 fold cross validation\n",
    " - fine-tune the kernel parameters for 2 selected kernels\n",
    " - show the ROC curve with the AUC value for the best model that you have found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_fin[features[3:]]\n",
    "y = df_fin['Hurricane']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_SVC(kernel='rbf'):\n",
    "    # 5-fold search is needed\n",
    "    folds = 5\n",
    "    cv = KFold(n_splits=folds, shuffle=True, random_state=42)\n",
    "    # SVC estimator\n",
    "    model = SVC(kernel=kernel, max_iter=-1, random_state=42)\n",
    "    # Paramters to explored:\n",
    "    # C : regularization strength\n",
    "    param_grid = {\n",
    "        'C' : np.logspace(-10, 1, 100),\n",
    "    }\n",
    "    # Grid search cross-validation\n",
    "    clf = GridSearchCV(estimator=model,\n",
    "                       param_grid=param_grid,\n",
    "                       cv=cv,\n",
    "                       n_jobs=-1)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4./a. First kernel: `linear`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = 'linear'\n",
    "clf = fit_SVC(kernel=kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "best_model = clf.fit(X_train, y_train).best_estimator_\n",
    "print('Best model : {0}'.format(best_model))\n",
    "y_pred = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and accuracy metric and the confusion matrix\n",
    "accuracy = accuracy_metric(y_test=y_test, y_pred=y_pred)\n",
    "conf_mat = confusion_matrix(y_test, y_pred, labels=[i for i in range(0,2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(conf_mat, y_test, labels=['Before', 'After'],\n",
    "                      title=('Fig. 10. Confusion matrix of the predictions on the\\n' +\n",
    "                             'test set using fine-tuned SVC with {0} kernel.\\n'.format(kernel) +\n",
    "                             'Accuracy of model is {0:.3f}%'.format(accuracy)),\n",
    "                     figsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_tr, tpr_tr, roc_auc_tr = compute_roc(best_model, X_train, y_train)\n",
    "fpr_ts, tpr_ts, roc_auc_ts = compute_roc(best_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize=(11, 11),\n",
    "                         facecolor='black', subplot_kw={'facecolor' : 'black'})\n",
    "\n",
    "axes.plot([0, 1], [0, 1], color=rocket_cmap(0.25), lw=5, linestyle='--')\n",
    "\n",
    "# My model\n",
    "axes.plot(fpr_tr, tpr_tr,\n",
    "          label='ROC curve [train] \\n(AUC = %0.3f)' % roc_auc_tr,\n",
    "          color=cm.magma(0.75), lw=4, alpha=0.8)\n",
    "axes.plot(fpr_ts, tpr_ts,\n",
    "          label='ROC curve [test] \\n(AUC = %0.3f)' % roc_auc_ts,\n",
    "          color=cm.magma(0.93), lw=4, alpha=0.8)\n",
    "\n",
    "axes.set_xlim([-0.02, 1.02])\n",
    "axes.set_ylim([-0.02, 1.02])\n",
    "\n",
    "axes.set_xlabel('False Positive Rate', fontsize=axislabelsize, fontweight='bold', color='white')\n",
    "axes.set_ylabel('True Positive Rate', fontsize=axislabelsize, fontweight='bold', color='white')\n",
    "axes.tick_params(axis='both', which='major', labelsize=axisticksize, colors='white')\n",
    "\n",
    "axes.legend(loc='lower right', fontsize=axislegendsize)\n",
    "\n",
    "plt.suptitle('Fig. 11. ROC curve of the fine-tuned SVC model,\\n' +\n",
    "             'with {0} kernel on the lizard-hurricane dataset.'.format(kernel),\n",
    "             fontsize=axistitlesize+5, y=0.04, color='white')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4./b. Second kernel: `poly`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = 'poly'\n",
    "clf = fit_SVC(kernel=kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "best_model = clf.fit(X_train, y_train).best_estimator_\n",
    "print('Best model : {0}'.format(best_model))\n",
    "y_pred = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and accuracy metric and the confusion matrix\n",
    "accuracy = accuracy_metric(y_test=y_test, y_pred=y_pred)\n",
    "conf_mat = confusion_matrix(y_test, y_pred, labels=[i for i in range(0,2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(conf_mat, y_test, labels=['Before', 'After'],\n",
    "                      title=('Fig. 12. Confusion matrix of the predictions on the\\n' +\n",
    "                             'test set using fine-tuned SVC with {0} kernel.\\n'.format(kernel) +\n",
    "                             'Accuracy of model is {0:.3f}%'.format(accuracy)),\n",
    "                     figsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_tr, tpr_tr, roc_auc_tr = compute_roc(best_model, X_train, y_train)\n",
    "fpr_ts, tpr_ts, roc_auc_ts = compute_roc(best_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize=(11, 11),\n",
    "                         facecolor='black', subplot_kw={'facecolor' : 'black'})\n",
    "\n",
    "axes.plot([0, 1], [0, 1], color=rocket_cmap(0.25), lw=5, linestyle='--')\n",
    "\n",
    "# My model\n",
    "axes.plot(fpr_tr, tpr_tr,\n",
    "          label='ROC curve [train] \\n(AUC = %0.3f)' % roc_auc_tr,\n",
    "          color=cm.magma(0.75), lw=4, alpha=0.8)\n",
    "axes.plot(fpr_ts, tpr_ts,\n",
    "          label='ROC curve [test] \\n(AUC = %0.3f)' % roc_auc_ts,\n",
    "          color=cm.magma(0.93), lw=4, alpha=0.8)\n",
    "\n",
    "axes.set_xlim([-0.02, 1.02])\n",
    "axes.set_ylim([-0.02, 1.02])\n",
    "\n",
    "axes.set_xlabel('False Positive Rate', fontsize=axislabelsize, fontweight='bold', color='white')\n",
    "axes.set_ylabel('True Positive Rate', fontsize=axislabelsize, fontweight='bold', color='white')\n",
    "axes.tick_params(axis='both', which='major', labelsize=axisticksize, colors='white')\n",
    "\n",
    "axes.legend(loc='lower right', fontsize=axislegendsize)\n",
    "\n",
    "plt.suptitle('Fig. 13. ROC curve of the fine-tuned SVC model,\\n' +\n",
    "             'with {0} kernel on the lizard-hurricane dataset.'.format(kernel),\n",
    "             fontsize=axistitlesize+5, y=0.04, color='white')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4./c. Third kernel: `rbf`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = 'rbf'\n",
    "clf = fit_SVC(kernel=kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "best_model = clf.fit(X_train, y_train).best_estimator_\n",
    "print('Best model : {0}'.format(best_model))\n",
    "y_pred = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and accuracy metric and the confusion matrix\n",
    "accuracy = accuracy_metric(y_test=y_test, y_pred=y_pred)\n",
    "conf_mat = confusion_matrix(y_test, y_pred, labels=[i for i in range(0,2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(conf_mat, y_test, labels=['Before', 'After'],\n",
    "                      title=('Fig. 14. Confusion matrix of the predictions on the\\n' +\n",
    "                             'test set using fine-tuned SVC with {0} kernel.\\n'.format(kernel) +\n",
    "                             'Accuracy of model is {0:.3f}%'.format(accuracy)),\n",
    "                     figsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_tr, tpr_tr, roc_auc_tr = compute_roc(best_model, X_train, y_train)\n",
    "fpr_ts, tpr_ts, roc_auc_ts = compute_roc(best_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize=(11, 11),\n",
    "                         facecolor='black', subplot_kw={'facecolor' : 'black'})\n",
    "\n",
    "axes.plot([0, 1], [0, 1], color=rocket_cmap(0.25), lw=5, linestyle='--')\n",
    "\n",
    "# My model\n",
    "axes.plot(fpr_tr, tpr_tr,\n",
    "          label='ROC curve [train] \\n(AUC = %0.3f)' % roc_auc_tr,\n",
    "          color=cm.magma(0.75), lw=4, alpha=0.8)\n",
    "axes.plot(fpr_ts, tpr_ts,\n",
    "          label='ROC curve [test] \\n(AUC = %0.3f)' % roc_auc_ts,\n",
    "          color=cm.magma(0.93), lw=4, alpha=0.8)\n",
    "\n",
    "axes.set_xlim([-0.02, 1.02])\n",
    "axes.set_ylim([-0.02, 1.02])\n",
    "\n",
    "axes.set_xlabel('False Positive Rate', fontsize=axislabelsize, fontweight='bold', color='white')\n",
    "axes.set_ylabel('True Positive Rate', fontsize=axislabelsize, fontweight='bold', color='white')\n",
    "axes.tick_params(axis='both', which='major', labelsize=axisticksize, colors='white')\n",
    "\n",
    "axes.legend(loc='lower right', fontsize=axislegendsize)\n",
    "\n",
    "plt.suptitle('Fig. 15. ROC curve of the fine-tuned SVC model,\\n' +\n",
    "             'with {0} kernel on the lizard-hurricane dataset.'.format(kernel),\n",
    "             fontsize=axistitlesize+5, y=0.04, color='white')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4./d. Fourth kernel: `sigmoid`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = 'sigmoid'\n",
    "clf = fit_SVC(kernel=kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "best_model = clf.fit(X_train, y_train).best_estimator_\n",
    "print('Best model : {0}'.format(best_model))\n",
    "y_pred = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and accuracy metric and the confusion matrix\n",
    "accuracy = accuracy_metric(y_test=y_test, y_pred=y_pred)\n",
    "conf_mat = confusion_matrix(y_test, y_pred, labels=[i for i in range(0,2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(conf_mat, y_test, labels=['Before', 'After'],\n",
    "                      title=('Fig. 16. Confusion matrix of the predictions on the\\n' +\n",
    "                             'test set using fine-tuned SVC with {0} kernel.\\n'.format(kernel) +\n",
    "                             'Accuracy of model is {0:.3f}%'.format(accuracy)),\n",
    "                     figsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_tr, tpr_tr, roc_auc_tr = compute_roc(best_model, X_train, y_train)\n",
    "fpr_ts, tpr_ts, roc_auc_ts = compute_roc(best_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize=(11, 11),\n",
    "                         facecolor='black', subplot_kw={'facecolor' : 'black'})\n",
    "\n",
    "axes.plot([0, 1], [0, 1], color=rocket_cmap(0.25), lw=5, linestyle='--')\n",
    "\n",
    "# My model\n",
    "axes.plot(fpr_tr, tpr_tr,\n",
    "          label='ROC curve [train] \\n(AUC = %0.3f)' % roc_auc_tr,\n",
    "          color=cm.magma(0.75), lw=4, alpha=0.8)\n",
    "axes.plot(fpr_ts, tpr_ts,\n",
    "          label='ROC curve [test] \\n(AUC = %0.3f)' % roc_auc_ts,\n",
    "          color=cm.magma(0.93), lw=4, alpha=0.8)\n",
    "\n",
    "axes.set_xlim([-0.02, 1.02])\n",
    "axes.set_ylim([-0.02, 1.02])\n",
    "\n",
    "axes.set_xlabel('False Positive Rate', fontsize=axislabelsize, fontweight='bold', color='white')\n",
    "axes.set_ylabel('True Positive Rate', fontsize=axislabelsize, fontweight='bold', color='white')\n",
    "axes.tick_params(axis='both', which='major', labelsize=axisticksize, colors='white')\n",
    "\n",
    "axes.legend(loc='lower right', fontsize=axislegendsize)\n",
    "\n",
    "plt.suptitle('Fig. 17. ROC curve of the fine-tuned SVC model,\\n' +\n",
    "             'with {0} kernel on the lizard-hurricane dataset.'.format(kernel),\n",
    "             fontsize=axistitlesize+5, y=0.04, color='white')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4./e. Conclusions\n",
    "\n",
    "So the best kernel for an SVC model was the `poly` kernel. All kernels were tested using the same random seed and all grid search tuning converged within the search interval."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. RF + feature importances\n",
    " - train and generate predictions with a random forest classifier model using leave 5 fold cross validation\n",
    " - show the ROC curve with the AUC value for the best model that you have found\n",
    " - train a random forest model on all the data and show the 5 most important features based on feature importances of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_fin[features[3:]]\n",
    "y = df_fin['Hurricane']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5./a. 5-fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5-fold search is needed\n",
    "folds = 5\n",
    "cv = KFold(n_splits=folds, shuffle=True, random_state=42)\n",
    "# LogisticRegression model\n",
    "model = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "# Paramters to explored:\n",
    "# C : max leaf nodes\n",
    "param_grid = {\n",
    "    'max_leaf_nodes' : np.arange(5, 100, 1),\n",
    "}\n",
    "# Grid search cross-validation\n",
    "clf = GridSearchCV(estimator=model,\n",
    "                   param_grid=param_grid,\n",
    "                   cv=cv,\n",
    "                   n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "best_model = clf.fit(X_train, y_train).best_estimator_\n",
    "print('Best model : {0}'.format(best_model))\n",
    "y_pred = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5./b. Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Create an RFE selection\n",
    "rfe = RFE(estimator=best_model, n_features_to_select=5, step=1)\n",
    "# Fit the selection with the best RandomForestClassifier model as an estimator\n",
    "rfe_rfc_model = rfe.fit(X_train, y_train)\n",
    "# Get predictions\n",
    "rfe_pred = rfe_rfc_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selected features\n",
    "features_sel = features[3:][rfe_rfc_model.support_]\n",
    "coef_sel = rfe_rfc_model.estimator_.feature_importances_\n",
    "# Sort them by coef_\n",
    "coef_sel, features_sel = zip(*sorted(zip(coef_sel, features_sel), reverse=True))\n",
    "# Calculate MAE and RMS\n",
    "rfc_mae = np.mean(np.abs(y_test - rfe_pred))\n",
    "rfc_rms = np.sqrt(np.mean((y_test - rfe_pred)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('RandomForestClassifier MAE: {0:.4f}'.format(rfc_mae))\n",
    "print('RandomForestClassifier RMS: {0:.4f}'.format(rfc_rms))\n",
    "print('Most prominent features:\\n'+\n",
    "      '---------------------------')\n",
    "[print('{0} : {1:.4f}'.format(f, c)) for (f, c) in zip(features_sel, coef_sel)];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5./c. Create predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and accuracy metric and the confusion matrix\n",
    "accuracy = accuracy_metric(y_test=y_test, y_pred=y_pred)\n",
    "conf_mat = confusion_matrix(y_test, y_pred, labels=[i for i in range(0,2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(conf_mat, y_test, labels=['Before', 'After'],\n",
    "                      title=('Fig. 18. Confusion matrix of the predictions\\n' +\n",
    "                             'on the test set using the RandomForestClassfier.\\n' +\n",
    "                             'Accuracy of model is {0:.3f}%'.format(accuracy)),\n",
    "                     figsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_tr, tpr_tr, roc_auc_tr = compute_roc(best_model, X_train, y_train)\n",
    "fpr_ts, tpr_ts, roc_auc_ts = compute_roc(best_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize=(11, 11),\n",
    "                         facecolor='black', subplot_kw={'facecolor' : 'black'})\n",
    "\n",
    "axes.plot([0, 1], [0, 1], color=rocket_cmap(0.25), lw=5, linestyle='--')\n",
    "\n",
    "# My model\n",
    "axes.plot(fpr_tr, tpr_tr,\n",
    "          label='ROC curve [train] \\n(AUC = %0.3f)' % roc_auc_tr,\n",
    "          color=cm.magma(0.75), lw=4, alpha=0.8)\n",
    "axes.plot(fpr_ts, tpr_ts,\n",
    "          label='ROC curve [test] \\n(AUC = %0.3f)' % roc_auc_ts,\n",
    "          color=cm.magma(0.93), lw=4, alpha=0.8)\n",
    "\n",
    "axes.set_xlim([-0.02, 1.02])\n",
    "axes.set_ylim([-0.02, 1.02])\n",
    "\n",
    "axes.set_xlabel('False Positive Rate', fontsize=axislabelsize, fontweight='bold', color='white')\n",
    "axes.set_ylabel('True Positive Rate', fontsize=axislabelsize, fontweight='bold', color='white')\n",
    "axes.tick_params(axis='both', which='major', labelsize=axisticksize, colors='white')\n",
    "\n",
    "axes.legend(loc='lower right', fontsize=axislegendsize)\n",
    "\n",
    "plt.suptitle('Fig. 19. ROC curve of the fine-tuned RandomForestClassfier,\\n' +\n",
    "             'model on the lizard-hurricane dataset.',\n",
    "             fontsize=axistitlesize+5, y=0.04, color='white')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hints:\n",
    " - On total you can get 10 points for fully completing all tasks.\n",
    " - Decorate your notebook with, questions, explanation etc, make it self contained and understandable!\n",
    " - Comments you code when necessary\n",
    " - Write functions for repetitive tasks!\n",
    " - Use the pandas package for data loading and handling\n",
    " - Use matplotlib and seaborn for plotting or bokeh and plotly for interactive investigation\n",
    " - Use the scikit learn package for almost everything\n",
    " - Use for loops only if it is really necessary!\n",
    " - Code sharing is not allowed between student! Sharing code will result in zero points.\n",
    " - If you use code found on web, it is OK, but, make its source clear! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
