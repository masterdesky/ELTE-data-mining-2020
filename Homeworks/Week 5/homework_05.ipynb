{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05. Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install a conda package in the current Jupyter kernel\n",
    "# xlrd package needs to be installed for pandas to open Excel files\n",
    "import sys\n",
    "! conda install --yes --prefix {sys.prefix} xlrd\n",
    "! conda install --yes --prefix {sys.prefix} lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = './data/'\n",
    "out = './out/'\n",
    "\n",
    "# Bold print for Jupyter Notebook\n",
    "b1 = '\\033[1m'\n",
    "b0 = '\\033[0m'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Just some matplotlib and seaborn parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axistitlesize = 20\n",
    "axisticksize = 17\n",
    "axislabelsize = 26\n",
    "axislegendsize = 23\n",
    "axistextsize = 20\n",
    "axiscbarfontsize = 15\n",
    "\n",
    "# Set axtick dimensions\n",
    "major_size = 6\n",
    "major_width = 1.2\n",
    "minor_size = 3\n",
    "minor_width = 1\n",
    "mpl.rcParams['xtick.major.size'] = major_size\n",
    "mpl.rcParams['xtick.major.width'] = major_width\n",
    "mpl.rcParams['xtick.minor.size'] = minor_size\n",
    "mpl.rcParams['xtick.minor.width'] = minor_width\n",
    "mpl.rcParams['ytick.major.size'] = major_size\n",
    "mpl.rcParams['ytick.major.width'] = major_width\n",
    "mpl.rcParams['ytick.minor.size'] = minor_size\n",
    "mpl.rcParams['ytick.minor.width'] = minor_width\n",
    "\n",
    "mpl.rcParams.update({'figure.autolayout': False})\n",
    "\n",
    "# Seaborn style settings\n",
    "sns.set_style({'axes.axisbelow': True,\n",
    "               'axes.edgecolor': '.8',\n",
    "               'axes.facecolor': 'white',\n",
    "               'axes.grid': True,\n",
    "               'axes.labelcolor': '.15',\n",
    "               'axes.spines.bottom': True,\n",
    "               'axes.spines.left': True,\n",
    "               'axes.spines.right': True,\n",
    "               'axes.spines.top': True,\n",
    "               'figure.facecolor': 'white',\n",
    "               'font.family': ['sans-serif'],\n",
    "               'font.sans-serif': ['Arial',\n",
    "                'DejaVu Sans',\n",
    "                'Liberation Sans',\n",
    "                'Bitstream Vera Sans',\n",
    "                'sans-serif'],\n",
    "               'grid.color': '.8',\n",
    "               'grid.linestyle': '--',\n",
    "               'image.cmap': 'rocket',\n",
    "               'lines.solid_capstyle': 'round',\n",
    "               'patch.edgecolor': 'w',\n",
    "               'patch.force_edgecolor': True,\n",
    "               'text.color': '.15',\n",
    "               'xtick.bottom': True,\n",
    "               'xtick.color': '.15',\n",
    "               'xtick.direction': 'in',\n",
    "               'xtick.top': True,\n",
    "               'ytick.color': '.15',\n",
    "               'ytick.direction': 'in',\n",
    "               'ytick.left': True,\n",
    "               'ytick.right': True})\n",
    "\n",
    "# Colorpalettes, colormaps, etc.\n",
    "sns.set_palette(palette='rocket')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Download data from https://science.sciencemag.org/content/359/6378/926 (supplementary materials). If you do not succeed, you will find _aar3247_Cohen_SM_Tables-S1-S11.xlsx_ file in the homework's folder.\n",
    " - read the abstract of the article to get familiar with data origin\n",
    " - open the data in excel and get familiar with its content\n",
    " - load the protein level data (you need to figure out which one is that) as a pandas dataframe\n",
    " - handle missing values and convert features to numeric values when it is needed\n",
    " - get rid of the unnecessary (which does not encode protein levels or the tumor type) columns and the CancerSEEK results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1./a. Open the protein dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Open file from URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import urllib.request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue\n",
    "\n",
    "Pandas somewhy can't handle I/O with excel files, when loading them from an `urllib3.response.HTTPResponse` object:\n",
    "\n",
    "- [Issue #20434](https://github.com/pandas-dev/pandas/issues/20434)\n",
    "- [Issue #28825](https://github.com/pandas-dev/pandas/issues/28825)\n",
    "\n",
    "It was said to be adressed in [Issue #28874](https://github.com/pandas-dev/pandas/pull/28874), but it seems that it wasn't, or maybe it was reintroduced in a newer release. At the end of the day this code simply doesn't work, however it should in normal circumstances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PANDAS BUG!\n",
    "#url = 'https://science.sciencemag.org/highwire/filestream/704651/field_highwire_adjunct_files/1/aar3247_Cohen_SM_Tables-S1-S11.xlsx'\n",
    "#with urllib.request.urlopen(url) as url:\n",
    "#    df = pd.read_excel(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Open file locally\n",
    "\n",
    "Open file using the local download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(data + 'aar3247_Cohen_SM_Tables-S1-S11.xlsx', sheet_name='Table S6', header=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.head())\n",
    "display(df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# last 4 columns are just comments\n",
    "df = df.iloc[:-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1./b. Handle missing values\n",
    "\n",
    "#### Possible problems of naive filling and solutions\n",
    "\n",
    "Handling columns with just a few ($< 10$) missing values is completely straightforward. However almost half of the values missing in the column `AJCC Stage`, which makes it somewhat more problematic on the first glance. However this feature only classifies cancerous patients from I to III by the stage of cancer. There are $812$ healthy people in the dataset with $812$ missing values in the `AJCC Stage` column. It is reasonable to fill these entries with zeros to indicate there are no, or just \"in situ\" cancerous cells were observed.\n",
    "\n",
    "#### Non-numeric columns\n",
    "\n",
    "There are numerous features with non-numeric entries, or numeric entries with appended non-numeric characters. First of all, the first two ID colums could be simply dropped, since they're completely artificial and random, thus do not carry any useful information. However there are three more features with useful data but in the form of columns with non-numeric entries. Particularly these are the columns `Tumor type`, `AJCC Stage` and `CancerSEEK Test Result`. The latter one is simply a binary data column, while `Tumor type` and `AJCC Stage` are categorical features with $9$ and $3$ categories respectively. These could be easily mapped to numeric values, which I'll do first before any other analysis or column filling.\n",
    "\n",
    "All other columns with NaN entries have continuous variables, thus we're able to fill missing entries with eg. the mean of existing values. However there is still one problem with these columns, but with other completely filled columns also. Besides NaNs, there is another type of values that represents itself in this dataset. These values are numeric, but in a string format with a `*` or `**` appended to the front of them. The meaning of these notations can be found in the original `.xlsx` Excel document, also in the tail of the very first, raw DataFrame in this notebook:\n",
    "\n",
    "- `*`  : Protein concentration below the limit of detection of the assay; value set as experiment-specific lower limit of detection  \n",
    "- `**` : Protein concentration above the limit of detection of the assay; value set as experiment-specific upper limit of detection\n",
    "\n",
    "Every occurence of this type of values should be converted to numeric to be able to use them in the analysis, or in the filling of missing entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('# of missing values in the dataset by features:')\n",
    "print('-----------------------------------------------')\n",
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame to temper with\n",
    "df_s = df.copy()\n",
    "df_s = df_s[df.columns[2:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1./b. - 1. Convert entries with appended `*` and `**` symbols to numeric\n",
    "\n",
    "Not the accepted, but the second most liked answer under this question is beautiful:  \n",
    "https://stackoverflow.com/questions/13682044/remove-unwanted-parts-from-strings-in-a-column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = df_s.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns with fully non-numeric entries\n",
    "# Can be checked by\n",
    "#     (df_n.applymap(type) == str).all(0),\n",
    "# but NaN values makes it problematic this makes it only partly useful/accurate\n",
    "str_columns = ['Tumor type', 'AJCC Stage', 'CancerSEEK Test Result']\n",
    "\n",
    "# Columns with fully numeric entries (NaN entries are ignored)\n",
    "nmr_columns = list([c for c in df_s.columns if c not in str_columns])\n",
    "\n",
    "# Create a map of numeric and non-numeric columns\n",
    "# Here `True` entries stand for non-numeric, while\n",
    "# `False` entries mark numeric values\n",
    "str_map = (df_s[nmr_columns].applymap(type) == str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(str_map.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stars(df, str_map):\n",
    "    \"\"\"\n",
    "    Remove asterisks from semi-numeric entries and convert them to floats\n",
    "    in a `pandas.DataFrame` object\n",
    "    \"\"\"\n",
    "    df_c = df.copy()\n",
    "    for c in str_map.columns:\n",
    "        if str_map[c].sum() > 0:\n",
    "            # Get `str` values from the column `c` of\n",
    "            # the `df_c` DataFrame. Indeces of `str` values\n",
    "            # are stored in the `str_map` DataFrame. \n",
    "            c_vals = df_c[c][str_map[c]]\n",
    "            indeces = list(c_vals.index)\n",
    "            df_c.loc[indeces, c] = c_vals.str.replace('*', '').astype(float)\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "    return df_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_n = remove_stars(df_s, str_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1./b. - 2. Map `Tumor type`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('# of different values in the column `Tumor type`:')\n",
    "print('-------------------------------------------------')\n",
    "print(df['Tumor type'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_tumor_type = {key : i+1 for i, key in enumerate(df['Tumor type'].value_counts().index)}\n",
    "df_n['Tumor type'] = df['Tumor type'].map(map_tumor_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('# of different values in the column `Tumor type`:')\n",
    "print('-------------------------------------------------')\n",
    "print(df_n['Tumor type'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1./b. - 3. Map `AJCC Stage`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Different values in the column `AJCC Stage`:')\n",
    "print('--------------------------------------------')\n",
    "print(df['AJCC Stage'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the `I`, `II` and `III` values in the `AJCC Stage` to numerical values first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_ajcc_stage = {'I' : 1, 'II' : 2, 'III' : 3}\n",
    "df_n['AJCC Stage'] = df_n['AJCC Stage'].map(map_ajcc_stage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Different values in the column `AJCC Stage`:')\n",
    "print('--------------------------------------------')\n",
    "print(df_n['AJCC Stage'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1./b. - 4. Map `CancerSEEK Test Result`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Different values in the column `CancerSEEK Test Result`:')\n",
    "print('--------------------------------------------------------')\n",
    "print(df['CancerSEEK Test Result'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the `I`, `II` and `III` values in the `AJCC Stage` to numerical values first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_cancer_test_res = {'Negative' : 0, 'Positive' : 1}\n",
    "df_n['CancerSEEK Test Result'] = df_n['CancerSEEK Test Result'].map(map_cancer_test_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Different values in the column `CancerSEEK Test Result`:')\n",
    "print('--------------------------------------------------------')\n",
    "print(df_n['CancerSEEK Test Result'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1./b. - 5. Fill every NaN entry in features except for the column `AJCC Stage`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_counts = df_n.isna().sum()\n",
    "nan_columns = [key for key in nan_counts.index if nan_counts[key] > 0]\n",
    "# Exclude the column `AJCC Stage`\n",
    "nan_columns.remove('AJCC Stage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_n[nan_columns].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_n[nan_columns] = df_n[nan_columns].fillna(df_n.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('# of missing values in the dataset by features after fill:')\n",
    "print('----------------------------------------------------------')\n",
    "df_n.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1./b. - 6. Fill missing entries in `AJCC Stage` with zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_n['AJCC Stage'] = df_n['AJCC Stage'].fillna(value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1./b. - 7. Add a Cancerous/Non-cancerous binary column to the table based on the feature `Tumor type`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_n['Cancerous'] = df_n['Tumor type'].map(lambda x: 0 if x==1 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_n.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1./b. - 8. Create a dictionary for tumor types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tumor_dict = {k : v for (k, v) in zip(df_n['Tumor type'].value_counts().index, df['Tumor type'].value_counts().index)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = df_n.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model.to_csv(data + 'final_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auxiliary function for further tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_classifier(X, y):\n",
    "    \n",
    "    # Split the data into train and test data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.5, random_state=0)\n",
    "\n",
    "    # Build the model with Logistic Regression wrapped inside an OVR strategy\n",
    "    classifier = OneVsRestClassifier(LogisticRegression(penalty='l2', max_iter=1000, random_state=0))\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    return classifier, X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_data(X):\n",
    "    \"\"\"\n",
    "    Normalize the data to have zero mean and unit variance.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X : ndarray or array-like in shape of (N, M)\n",
    "        The unscaled dataset.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    X : ndarray in shape of (N, M)\n",
    "        The already scaled dataset with zero mean and unit variance.\n",
    "    \"\"\"\n",
    "    # Initialize\n",
    "    scaler = StandardScaler()\n",
    "    # Compute the mean and standard dev. and scale the dataset `X`\n",
    "    X = scaler.fit_transform(X)\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_metric(y_test, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate accuracy of model prediction.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    y_test : array-like of shape (N, )\n",
    "        Original labels of the test dataset.\n",
    "    \n",
    "    y_pred : array-like of shape (N, )\n",
    "        Predicted labels of the test dataset.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    Accuracy of model in reference of the true test labels.\n",
    "    \"\"\"\n",
    "    y_test = np.array(y_test)\n",
    "    y_pred = np.array(y_pred)\n",
    "\n",
    "    correct = 0\n",
    "    for (t, p) in zip(y_test, y_pred):\n",
    "        if hasattr(t, '__len__'):\n",
    "            t = list(t)\n",
    "            p = list(p)\n",
    "        if t == p:\n",
    "            correct += 1\n",
    "    return correct / len(y_test) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(conf_mat, classes, title=None):\n",
    "    \"\"\"\n",
    "    Plots a confusion matrix\n",
    "    \"\"\"\n",
    "    size_factor = conf_mat.shape[0] / 3\n",
    "    \n",
    "    fig, axes = plt.subplots(figsize=(4*size_factor, 4*size_factor))\n",
    "    axes.set_aspect('equal')\n",
    "\n",
    "    im = axes.imshow(conf_mat)\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    for X in range(conf_mat.shape[0]):\n",
    "        for Y in range(conf_mat.shape[1]):\n",
    "            axes.text(Y, X, conf_mat[X, Y], fontsize=30,\n",
    "                      ha='center', va='center', color='white', fontweight='bold', \n",
    "                      bbox=dict(color=np.array((0,0,0,0.2)), lw=0)\n",
    "                     )\n",
    "    #'top', 'bottom', 'center', 'baseline', 'center_baseline'\n",
    "    ticks = [i for i in range(len(classes))]\n",
    "    axes.set_xticks(ticks)\n",
    "    axes.set_xticklabels(classes, ha='center')\n",
    "    axes.set_yticks(ticks)\n",
    "    axes.set_yticklabels(classes, va='center_baseline')\n",
    "\n",
    "    axes.set_xlabel('Predicted labels', fontsize=axislabelsize, fontweight='bold')\n",
    "    axes.set_ylabel('True labels', fontsize=axislabelsize, fontweight='bold')\n",
    "    axes.tick_params(axis='both', which='major', labelsize=axisticksize, rotation=42)\n",
    "    axes.xaxis.tick_top()\n",
    "    axes.xaxis.set_label_position('top') \n",
    "\n",
    "    axes.grid(False)\n",
    "\n",
    "    # Create an axis on the right side of `axes`. The width of `cax` will be 5%\n",
    "    # of `axes` and the padding between `cax` and axes will be fixed at 0.1 inch\n",
    "    divider = make_axes_locatable(axes)\n",
    "    cax = divider.append_axes('right', size='5%', pad=0.1)\n",
    "    cbar = plt.colorbar(mappable=im, cax=cax)\n",
    "    cbar.ax.tick_params(labelsize=axiscbarfontsize, colors='black')\n",
    "    cbar.set_label('Number of occurences', fontsize=axiscbarfontsize+10, labelpad=15, rotation=90)\n",
    "\n",
    "    plt.suptitle(title,\n",
    "                 fontsize=axistitlesize, y=0.1)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_roc_multi(y_test, y_pred, n_classes=1):\n",
    "    \"\"\"\n",
    "    Compute the ROC and area under the ROC curve for all classes\n",
    "    Usage can be found at:\n",
    "        ```https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html```\n",
    "    \"\"\"\n",
    "    # Compute ROC curve and ROC area for each class\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(n_classes):\n",
    "        if n_classes > 1:\n",
    "            y_t = y_test[:, i]\n",
    "            y_p = y_pred[:, i]\n",
    "        else:\n",
    "            y_t = y_test\n",
    "            y_p = y_pred\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_t, y_p)\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    # Compute micro-average ROC curve and ROC area\n",
    "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_pred.ravel())\n",
    "    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "    \n",
    "    return fpr, tpr, roc_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Predict if a sample is cancerous or not\n",
    " - you need to build a classifier that predicts the probability of a sample coming from a cancerous (tumor type is normal or not) person based on the measured protein levels\n",
    " - train a logistic regression (sklearn API) on every second sample (not first 50% of the data (!), use every second line)\n",
    " - generate prediction for the samples that were not used during the training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm using a random 50%-50% train/test split with set seed for reproducibility."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2./a. Predict whether a data is from cancerous patient or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observables are the protein levels\n",
    "X = df_model[df_model.columns[2:-3]].copy()\n",
    "# Scale features with continuous variables\n",
    "X = pd.DataFrame(scale_data(X), columns=X.columns)\n",
    "\n",
    "# The target variable is 'Cancerous'\n",
    "y = df_model['Cancerous']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier, X_train, X_test, y_train, y_test = fit_classifier(X, y)\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values = shap.LinearExplainer(classifier, X_train).shap_values(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X_test,\n",
    "                  max_display=16, class_names=['Non-cancerous', 'Cancerous'],\n",
    "                  layered_violin_max_num_bins=20, alpha=0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Comparision to CancerSEEK\n",
    " - plot the ROC curve and calculate the confusion matrix for the predictions\n",
    " - do the same for the CancerSEEK predictions\n",
    " - compare your model's performance to CancerSEEK performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3./a. Plot confusion matrix and calculate accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating accuracy and the confusion matrix\n",
    "accuracy = accuracy_metric(y_test.ravel(), y_pred)\n",
    "conf_mat = confusion_matrix(y_test.ravel(), y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['Cancerous', 'Non-cancerous']\n",
    "title=('Fig. 2. Confusion matrix of the cancer identification\\n' +\n",
    "       'by protein levels.\\n' +\n",
    "       'Accuracy of model is {0:.3f}%'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize=(7, 7))\n",
    "axes.set_aspect('equal')\n",
    "\n",
    "im = axes.imshow(conf_mat)\n",
    "# Loop over data dimensions and create text annotations.\n",
    "for X in range(conf_mat.shape[0]):\n",
    "    for Y in range(conf_mat.shape[1]):\n",
    "        axes.text(Y, X, conf_mat[X, Y], fontsize=30,\n",
    "                  ha='center', va='center', color='white', fontweight='bold', \n",
    "                  bbox=dict(color=np.array((0,0,0,0.2)), lw=0)\n",
    "                 )\n",
    "\n",
    "ticks = [i for i in range(len(classes))]\n",
    "axes.set_xticks(ticks)\n",
    "axes.set_xticklabels(classes, ha='center')\n",
    "axes.set_yticks(ticks)\n",
    "axes.set_yticklabels(classes, va='center_baseline')\n",
    "\n",
    "axes.set_xlabel('Predicted labels', fontsize=axislabelsize, fontweight='bold')\n",
    "axes.set_ylabel('True labels', fontsize=axislabelsize, fontweight='bold')\n",
    "axes.tick_params(axis='both', which='major', labelsize=axisticksize, rotation=42)\n",
    "axes.xaxis.tick_top()\n",
    "axes.xaxis.set_label_position('top') \n",
    "\n",
    "axes.grid(False)\n",
    "\n",
    "# Create an axis on the right side of `axes`. The width of `cax` will be 5%\n",
    "# of `axes` and the padding between `cax` and axes will be fixed at 0.1 inch\n",
    "divider = make_axes_locatable(axes)\n",
    "cax = divider.append_axes('right', size='5%', pad=0.1)\n",
    "cbar = plt.colorbar(mappable=im, cax=cax)\n",
    "cbar.ax.tick_params(labelsize=axiscbarfontsize, colors='black')\n",
    "cbar.set_label('Number of occurences', fontsize=axiscbarfontsize+10, labelpad=15, rotation=90)\n",
    "\n",
    "plt.suptitle(title,\n",
    "             fontsize=axistitlesize, y=0.1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3./b. Plot ROC and calculate AOC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, roc_auc = cal_roc_multi(y_test, y_pred, n_classes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = 1\n",
    "ncols = 1\n",
    "fig, axes = plt.subplots(nrows, ncols, figsize=(ncols*10, nrows*10))\n",
    "\n",
    "axes.plot(fpr[0], tpr[0], color='darkorange',\n",
    "          lw=3, label='ROC curve (area = %0.2f)' % roc_auc[0])\n",
    "axes.plot([0, 1], [0, 1], color='navy', lw=3, linestyle='--')\n",
    "\n",
    "axes.set_xlim([0.0, 1.0])\n",
    "axes.set_ylim([0.0, 1.0])\n",
    "\n",
    "axes.set_title('Receiver Operating Characteristic', fontsize=axistitlesize, fontweight='bold')\n",
    "axes.set_xlabel('False Positive Rate', fontsize=axislabelsize, fontweight='bold')\n",
    "axes.set_ylabel('True Positive Rate', fontsize=axislabelsize, fontweight='bold')\n",
    "axes.tick_params(axis='both', which='major', labelsize=axisticksize)\n",
    "\n",
    "axes.legend(loc='lower right', fontsize=axislegendsize)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Hepatocellular carcinoma\n",
    " - fit a logistic regression (using statsmodels API this time) to predict if a sample has Hepatocellular carcinoma (liver cancer) or not. You need to keep only the liver and the normal samples for this exercise! For fitting use only the first 25 features and all the rows (which are liver or normal)\n",
    " - select the 5 best predictor based on P values.\n",
    " - Write down the most important features (based on P value) and compare them to the tumor markers that you find on wikipeida https://en.wikipedia.org/wiki/Hepatocellular_carcinoma or other sources!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4./a. Logistic regression using `statsmodels`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observables are the protein levels\n",
    "X = df_model[df_model.columns[2:-3]].copy()\n",
    "# Select only `Normal` and `Liver` tumor types\n",
    "selection_map = (df['Tumor type'] == 'Normal') | (df['Tumor type'] == 'Liver')\n",
    "X = X[selection_map][X.columns[:25]]\n",
    "# Scale features with continuous variables\n",
    "X = pd.DataFrame(scale_data(X), columns=X.columns)\n",
    "\n",
    "# The target variable is 'Cancerous'\n",
    "y = label_binarize(df_model.loc[selection_map, 'Tumor type'], classes=[1, 9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = sm.Logit(y, X).fit()\n",
    "print(log_reg.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4./b. Select best 5 predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def results_summary_to_dataframe(results):\n",
    "    '''take the result of an statsmodel results table and transforms it into a dataframe'''\n",
    "    pvals = results.pvalues\n",
    "    coeff = results.params\n",
    "    conf_lower = results.conf_int()[0]\n",
    "    conf_higher = results.conf_int()[1]\n",
    "\n",
    "    results_df = pd.DataFrame({\"pvals\":pvals,\n",
    "                               \"coeff\":coeff,\n",
    "                               \"conf_lower\":conf_lower,\n",
    "                               \"conf_higher\":conf_higher\n",
    "                                })\n",
    "\n",
    "    #Reordering...\n",
    "    results_df = results_df[[\"coeff\",\"pvals\",\"conf_lower\",\"conf_higher\"]]\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_values = log_reg.pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_values_val, p_values_key = zip(*sorted(zip(list(p_values.values), list(p_values.index))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 5\n",
    "print('Most 5 impactful biomarkers:\\n'+\n",
    "      '----------------------------')\n",
    "print(tabulate([[k, v] for (k, v) in zip(p_values_key[-N:][::-1], p_values_val[-N:][::-1])], headers=['Biomarker', 'Value']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Multiclass classification\n",
    " - Again, using every second datapoint train a logistic regression (sklearn API) to predict the tumor type. It is a multiclass classification problem.\n",
    " - Generate prediction for the rest of the dataset and show the confusion matrix for the predictions!\n",
    " - Plot the ROC curves for the different cancer types on the same plot! \n",
    " - Intepret your results. Which cancer type can be predicted the most reliably?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5./a. Generate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_classifier(X, y):\n",
    "    \n",
    "    # Split the data into train and test data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.5, random_state=0)\n",
    "\n",
    "    # Build the model with Logistic Regression wrapped inside an OVR strategy\n",
    "    classifier = OneVsRestClassifier(LogisticRegression(penalty='l2', max_iter=1000, random_state=0))\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    return classifier, X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observables are the protein levels\n",
    "X = df_model[df_model.columns[2:-3]].copy()\n",
    "# Scale features with continuous variables\n",
    "X = pd.DataFrame(scale_data(X), columns=X.columns)\n",
    "\n",
    "# The target variable is 'Tumor type'\n",
    "y = df_model['Tumor type']\n",
    "y = label_binarize(y, classes=list(set(df_model['Tumor type'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier, X_train, X_test, y_train, y_test = fit_classifier(X, y)\n",
    "y_pred = classifier.decision_function(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values = shap.LinearExplainer(classifier, X_train).shap_values(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X_test,\n",
    "                  max_display=16, class_names=list(df['Tumor type'].value_counts().index),\n",
    "                  layered_violin_max_num_bins=20, alpha=0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5./b. Confusion matrix and accuracy of predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_metric(y_test=y_test, y_pred=y_pred)\n",
    "conf_mat = confusion_matrix(np.argmax(y_test, axis=1), np.argmax(y_pred, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title=('Fig. 3. Confusion matrix of the tumor type recognition\\n' +\n",
    "       'Accuracy of model is {0:.3f}%'.format(accuracy))\n",
    "classes = list(tumor_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize=(14, 14))\n",
    "axes.set_aspect('equal')\n",
    "\n",
    "im = axes.imshow(conf_mat)\n",
    "# Loop over data dimensions and create text annotations.\n",
    "for X in range(conf_mat.shape[0]):\n",
    "    for Y in range(conf_mat.shape[1]):\n",
    "        axes.text(Y, X, conf_mat[X, Y], fontsize=30,\n",
    "                  ha='center', va='center', color='white', fontweight='bold', \n",
    "                  bbox=dict(color=np.array((0,0,0,0.2)), lw=0)\n",
    "                 )\n",
    "\n",
    "ticks = [i for i in range(len(classes))]\n",
    "axes.set_xticks(ticks)\n",
    "axes.set_xticklabels(classes, ha='center')\n",
    "axes.set_yticks(ticks)\n",
    "axes.set_yticklabels(classes, va='center_baseline')\n",
    "\n",
    "axes.set_xlabel('Predicted labels', fontsize=axislabelsize, fontweight='bold')\n",
    "axes.set_ylabel('True labels', fontsize=axislabelsize, fontweight='bold')\n",
    "axes.tick_params(axis='both', which='major', labelsize=axisticksize, rotation=42)\n",
    "axes.xaxis.tick_top()\n",
    "axes.xaxis.set_label_position('top') \n",
    "\n",
    "axes.grid(False)\n",
    "\n",
    "# Create an axis on the right side of `axes`. The width of `cax` will be 5%\n",
    "# of `axes` and the padding between `cax` and axes will be fixed at 0.1 inch\n",
    "divider = make_axes_locatable(axes)\n",
    "cax = divider.append_axes('right', size='5%', pad=0.1)\n",
    "cbar = plt.colorbar(mappable=im, cax=cax)\n",
    "cbar.ax.tick_params(labelsize=axiscbarfontsize, colors='black')\n",
    "cbar.set_label('Number of occurences', fontsize=axiscbarfontsize+10, labelpad=15, rotation=90)\n",
    "\n",
    "plt.suptitle(title,\n",
    "             fontsize=axistitlesize+8, y=0.1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5./c. ROC curve of different classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, roc_auc = cal_roc_multi(y_test, y_pred, n_classes=len(set(df_model['Tumor type'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = 3\n",
    "ncols = 3\n",
    "fig, axes = plt.subplots(nrows, ncols, figsize=(ncols*10, nrows*10))\n",
    "\n",
    "for k in list(fpr.keys())[:-1]:\n",
    "    i = k // nrows\n",
    "    j = k % ncols\n",
    "    ax = axes[i][j]\n",
    "    ax.plot(fpr[k], tpr[k],\n",
    "              lw=3, label='ROC curve (area = %0.2f)' % roc_auc[k])\n",
    "    ax.plot([0, 1], [0, 1], color='navy', lw=3, linestyle='--')\n",
    "    ax.plot(fpr['micro'], tpr['micro'], color='darkorange',\n",
    "            lw=3, label='ROC curve micro (area = %0.2f)' % roc_auc['micro'])\n",
    "\n",
    "    ax.set_xlim([0.0, 1.0])\n",
    "    ax.set_ylim([0.0, 1.0])\n",
    "\n",
    "    ax.set_title('Tumor type : {0}'.format(tumor_dict[k+1]), fontsize=axistitlesize, fontweight='bold')\n",
    "    ax.set_xlabel('False Positive Rate', fontsize=axislabelsize, fontweight='bold')\n",
    "    ax.set_ylabel('True Positive Rate', fontsize=axislabelsize, fontweight='bold')\n",
    "    ax.tick_params(axis='both', which='major', labelsize=axisticksize)\n",
    "\n",
    "    ax.legend(loc='lower right', fontsize=axislegendsize)\n",
    "\n",
    "plt.suptitle('Fig. 4. ROC curves for all different Tumor types in the dataset',\n",
    "             fontsize=axistitlesize+17, y=0.06)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems to be, that pancreas and ovary cancer are identified the most reliably, as indicated by the area under the ROC curve. Not-so surprisingly, the reliable detection of breast cancer is the lowest by far."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hints:\n",
    " - On total you can get 10 points for fully completing all tasks.\n",
    " - Decorate your notebook with, questions, explanation etc, make it self contained and understandable!\n",
    " - Comments you code when necessary\n",
    " - Write functions for repetitive tasks!\n",
    " - Use the pandas package for data loading and handling\n",
    " - Use matplotlib and seaborn for plotting or bokeh and plotly for interactive investigation\n",
    " - Use the scikit learn package for almost everything\n",
    " - Use for loops only if it is really necessary!\n",
    " - Code sharing is not allowed between student! Sharing code will result in zero points.\n",
    " - If you use code found on web, it is OK, but, make its source clear!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
