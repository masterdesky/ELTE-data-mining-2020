{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully connected neural networks\n",
    "\n",
    "<u>On kooplex tensorflow 2 does not work, please work on Google Colab and then upload your solution to kooplex! Also, on Google Colab you can use GPUs</u>\n",
    "\n",
    "\n",
    "This week we will use the MNIST handwritten digits dataset! The weights.npy file is provided, which contains the weight vector for a traines fully connected neural network.\n",
    "\n",
    "#### 1 - 2. Implement fully connected neural network via using only numpy\n",
    "\n",
    "In this task we need to implement a small fully connected neural network that can generate predictions for us if we provide the weights and the input data!\n",
    "\n",
    " - implement the following function:\n",
    " ```python\n",
    " def pred_nn(weights, x_test):\n",
    "    ...\n",
    "    return predictions\n",
    " ```\n",
    " - x_test has a shape of (N_samples, 784)\n",
    " - predictions has a shape of (N_samples, 10)\n",
    " - then function implements a fully connected neural network with the follwing layers:\n",
    "    - 750 neuron, relu activation\n",
    "    - 500 neuron, relu activation\n",
    "    - 500 neuron, relu activation\n",
    "    - 10 neuron, softmax activation\n",
    " - weights is a numpy array of the weights\n",
    "    - 1st element is a shape of (784, 750), 2nd is (750,), the bias\n",
    "    - 3rd element is a shape of (750, 500), 4th is (500,)\n",
    "    ... the rest matches the weight dimensions of the above-mentioned architecture\n",
    " - use numpy's built-in vectorized operations, try not to write for loops!\n",
    "    \n",
    "An optimally implemented function runs < 1s for N_samples = 10.000 \n",
    "\n",
    "#### 3.  Same architecture via tensorflow/keras\n",
    "\n",
    " - Implement the same architecture with tensorflow/keras as we did in 1-2). \n",
    " - Load the provided weights for the neural network!\n",
    " \n",
    "#### 4-5. Compate performances\n",
    " - load the MNIST dataset from the tensorflow/keras built-in dataset\n",
    " - use the original train/test split!\n",
    " - divide each pixel's value by 255 & reshape to have 1D input vector (784) instead of the 2D matrix (28x28)\n",
    "   - eg for the test set you will have a (10000, 784) shaped vector\n",
    " - generate prediction for the 10.000 test images with both methods!\n",
    " - calculate the categorical cross-entropy loss and the accuracy for both methods! are they the same? (if not, it indicates a bug somewhere...) Hint: you should get ~97% accuracy\n",
    " - show the confusion matrix of the predictions (predicted values vs actual labels)\n",
    " - where does the model make mistakes?\n",
    "\n",
    "\n",
    "### Hints:\n",
    " - On total you can get 10 points for fully completing all tasks.\n",
    " - Decorate your notebook with, questions, explanation etc, make it self contained and understandable!\n",
    " - Comments you code when necessary\n",
    " - Write functions for repetitive tasks!\n",
    " - Use the pandas package for data loading and handling\n",
    " - Use matplotlib and seaborn for plotting or bokeh and plotly for interactive investigation\n",
    " - Use the scikit learn package for almost everything\n",
    " - Use for loops only if it is really necessary!\n",
    " - Code sharing is not allowed between student! Sharing code will result in zero points.\n",
    " - If you use code found on web, it is OK, but, make its source clear! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
