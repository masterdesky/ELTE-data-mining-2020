{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "315DLxAdHjPC"
   },
   "source": [
    "# HW 11.\n",
    "\n",
    "* Running the models may take minutes. This HW takes ~30 min to complete in computational time, so make sure you don't start it 1 hour before it is due.\n",
    "\n",
    "* Tasks 2-4. should be done using the `sklearn` library, the last is a pure TensorFlow ([Keras is part of TensorFlow](https://github.com/keras-team/keras/releases#:~:text=since%20this%20release-,Keras%202.2.,well%20as%20Theano%20and%20CNTK)) example.\n",
    "\n",
    "  * Use tf.keras instead of the standalone keras package\n",
    "\n",
    "* The example notebook was run in Google COLAB without any package installation. I advise you to use Google COLAB with a GPU instance for the last task.\n",
    "\n",
    "* Where not asked otherwise, use the default settings for the model.\n",
    "\n",
    "* You may try running the models using more CPU cores to speed the training (sklearn supports for most of the models with a parameter, usually n_jobs)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compatibility notes\n",
    "\n",
    "I've used TensorFlow's nightly builds `2.5.0-dev20201127` and `2.5.0-dev20201128` with `CUDA 11.0_2` and `cuDNN 8.0.5` support on my own computer's GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as plticker\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hw_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "import tensorflow.keras.callbacks as kc\n",
    "\n",
    "import sklearn\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = './data/'\n",
    "out = './out/'\n",
    "\n",
    "# Bold print for Jupyter Notebook\n",
    "b1 = '\\033[1m'\n",
    "b0 = '\\033[0m'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Just some matplotlib and seaborn parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axistitlesize = 20\n",
    "axisticksize = 17\n",
    "axislabelsize = 26\n",
    "axislegendsize = 23\n",
    "axistextsize = 20\n",
    "axiscbarfontsize = 15\n",
    "\n",
    "# Set axtick dimensions\n",
    "major_size = 6\n",
    "major_width = 1.2\n",
    "minor_size = 3\n",
    "minor_width = 1\n",
    "mpl.rcParams['xtick.major.size'] = major_size\n",
    "mpl.rcParams['xtick.major.width'] = major_width\n",
    "mpl.rcParams['xtick.minor.size'] = minor_size\n",
    "mpl.rcParams['xtick.minor.width'] = minor_width\n",
    "mpl.rcParams['ytick.major.size'] = major_size\n",
    "mpl.rcParams['ytick.major.width'] = major_width\n",
    "mpl.rcParams['ytick.minor.size'] = minor_size\n",
    "mpl.rcParams['ytick.minor.width'] = minor_width\n",
    "\n",
    "mpl.rcParams.update({'figure.autolayout': False})\n",
    "\n",
    "# Seaborn style settings\n",
    "sns.set_style({'axes.axisbelow': True,\n",
    "               'axes.edgecolor': '.8',\n",
    "               'axes.facecolor': 'white',\n",
    "               'axes.grid': True,\n",
    "               'axes.labelcolor': '.15',\n",
    "               'axes.spines.bottom': True,\n",
    "               'axes.spines.left': True,\n",
    "               'axes.spines.right': True,\n",
    "               'axes.spines.top': True,\n",
    "               'figure.facecolor': 'white',\n",
    "               'font.family': ['sans-serif'],\n",
    "               'font.sans-serif': ['Arial',\n",
    "                'DejaVu Sans',\n",
    "                'Liberation Sans',\n",
    "                'Bitstream Vera Sans',\n",
    "                'sans-serif'],\n",
    "               'grid.color': '.8',\n",
    "               'grid.linestyle': '--',\n",
    "               'image.cmap': 'rocket',\n",
    "               'lines.solid_capstyle': 'round',\n",
    "               'patch.edgecolor': 'w',\n",
    "               'patch.force_edgecolor': True,\n",
    "               'text.color': '.15',\n",
    "               'xtick.bottom': True,\n",
    "               'xtick.color': '.15',\n",
    "               'xtick.direction': 'in',\n",
    "               'xtick.top': True,\n",
    "               'ytick.color': '.15',\n",
    "               'ytick.direction': 'in',\n",
    "               'ytick.left': True,\n",
    "               'ytick.right': True})\n",
    "\n",
    "# Colorpalettes, colormaps, etc.\n",
    "sns.set_palette(palette='rocket')\n",
    "rocket_cmap = sns.color_palette('rocket', as_cmap=True)\n",
    "\n",
    "target_colors = np.array([cm.magma(0.5), cm.magma(0.75), cm.magma(0.93)])\n",
    "feature_colors = np.array([rocket_cmap(0.17), cm.magma(0.45), cm.magma(0.60), cm.magma(0.75)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load the CIFAR 10 dataset from the `tf.keras.datasets` API and train a `LogisticRegression` model on the dataset and predict all test outcomes with the `sklearn` API\n",
    "\n",
    "* Create an image grid visualization of randomly selected images (9, 16) with labels.\n",
    "* Preprocess the dataset for `sklearn`, scale the pixels [0-1], and also flatten each example to a vector.\n",
    "* Use the `multi_class='multinomial'` option, describe what it means.\n",
    "* Plot the ROC curves and AUC scores on the same figure for each class.\n",
    "* Calculate the accuracy of the classifier on the test set.\n",
    "\n",
    "Hint:\n",
    "* `from sklearn.preprocessing import LabelBinarizer` might be useful for you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1./a. Load and preprocess the CIFAR10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CIFAR 10 dataset\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('X_train shape :', X_train.shape)\n",
    "print('y_train shape :', y_train.shape)\n",
    "print('X_test shape :', X_test.shape)\n",
    "print('y_test shape :', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Look at some random images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = 3\n",
    "ncols = 8\n",
    "fig, axes = plt.subplots(nrows, ncols, figsize=(ncols*2, nrows*2),\n",
    "                         facecolor='black', subplot_kw={'facecolor' : 'black'})\n",
    "fig.subplots_adjust(hspace=0.5)\n",
    "\n",
    "rand_idx = np.random.randint(0, len(X_train), size=nrows*ncols)\n",
    "images = X_train[rand_idx]\n",
    "labels = y_train[rand_idx]\n",
    "\n",
    "for i, ax in enumerate(axes.reshape(-1)):\n",
    "    ax.imshow(images[i], cmap='Greys_r')\n",
    "    ax.set_title('Label : {0}'.format(labels[i]), fontweight='bold',\n",
    "                 color='white', pad=0)\n",
    "    ax.axis('off')\n",
    "    ax.grid(False)\n",
    "\n",
    "plt.suptitle('Fig. 1. Sample data along with their labels of the CIFAR10 dataset.',\n",
    "             color='white', fontsize=axistitlesize+5, y=0.1)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scale and flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale data\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "# Reshape data\n",
    "X_train = X_train.reshape((-1, 32*32*3))\n",
    "X_test = X_test.reshape((-1, 32*32*3))\n",
    "# Reshape labels to shape of (n_samples, )\n",
    "y_train = y_train.reshape(y_train.size, )\n",
    "y_test = y_test.reshape(y_test.size, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('X_train shape :', X_train.shape)\n",
    "print('y_train shape :', y_train.shape)\n",
    "print('X_test shape :', X_test.shape)\n",
    "print('y_test shape :', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1./b. Fit logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DEFINE LOGISTIC-REGRESSION\n",
    "# The meaning of the `multi_class` argument set to 'multinomial' is\n",
    "# explaned in the docstring of the `LogisticRegression` function:\n",
    "# > \"For 'multinomial' the loss minimised is the multinomial loss fit\n",
    "# > across the entire probability distribution, *even when the data is\n",
    "# > binary*.\"\n",
    "model_ex1 = LogisticRegression(penalty='l2', C=1.0, multi_class='multinomial',\n",
    "                               max_iter=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Fit model\n",
    "model_ex1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pickling\n",
    "- Save models if all of them were fitted\n",
    "- Load models if there is a saved instance of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_file = './models/saved_models_ex1'\n",
    "with open(pickle_file, 'wb') as f:\n",
    "    pickle.dump(model_ex1, f)\n",
    "if os.path.exists(pickle_file):\n",
    "    with open(pickle_file, 'rb') as f:\n",
    "        model_ex1 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1./c. Make predictions with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_ex1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and accuracy metric and the confusion matrix\n",
    "accuracy = accuracy_metric(y_test=y_test, y_pred=y_pred)\n",
    "conf_mat = confusion_matrix(y_test, y_pred, labels=[i for i in range(0,10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(conf_mat, y_test, labels=[i for i in range(0,10)],\n",
    "                      title=('Fig. 2. Confusion matrix of the predictions\\n' +\n",
    "                             'on the CIFAR10 dataset using the LogisticRegression model.\\n' +\n",
    "                             'Accuracy of model is {0:.3f}%'.format(accuracy)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_tr, tpr_tr, roc_auc_tr = compute_roc(model_ex1, X_train, y_train)\n",
    "fpr_ts, tpr_ts, roc_auc_ts = compute_roc(model_ex1, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize=(11, 11),\n",
    "                         facecolor='black', subplot_kw={'facecolor' : 'black'})\n",
    "\n",
    "axes.plot([0, 1], [0, 1], color=rocket_cmap(0.25), lw=5, linestyle='--')\n",
    "\n",
    "# My model\n",
    "axes.plot(fpr_tr, tpr_tr,\n",
    "          label='ROC curve [train] \\n(AUC = %0.3f)' % roc_auc_tr,\n",
    "          color=cm.magma(0.75), lw=4, alpha=0.8)\n",
    "axes.plot(fpr_ts, tpr_ts,\n",
    "          label='ROC curve [test] \\n(AUC = %0.3f)' % roc_auc_ts,\n",
    "          color=cm.magma(0.93), lw=4, alpha=0.8)\n",
    "\n",
    "axes.set_xlim([-0.02, 1.02])\n",
    "axes.set_ylim([-0.02, 1.02])\n",
    "\n",
    "axes.set_xlabel('False Positive Rate', fontsize=axislabelsize, fontweight='bold', color='white')\n",
    "axes.set_ylabel('True Positive Rate', fontsize=axislabelsize, fontweight='bold', color='white')\n",
    "axes.tick_params(axis='both', which='major', labelsize=axisticksize, colors='white')\n",
    "\n",
    "axes.legend(loc='lower right', fontsize=axislegendsize)\n",
    "\n",
    "plt.suptitle('Fig. 3. ROC curve of the LogisticRegression model,\\n' +\n",
    "             'on the CIFAR10 dataset.',\n",
    "             fontsize=axistitlesize+5, y=0.04, color='white')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train an `SGDClassifier` regression model on the dataset and predict all the test outcomes with the `sklearn` API. \n",
    "\n",
    "* Select an appropiate loss for this task, explain what this means.\n",
    "* Time is precious, run the classifier paralell on many jobs.\n",
    "* Plot the ROC curves and AUC scores on the same figure for the test set.\n",
    "* Calculate the accuracy of the classifier.\n",
    "* Describe the above model with your own words, how is it different than the logistic regression model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2./a. Load and preprocess the CIFAR10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CIFAR 10 dataset\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('X_train shape :', X_train.shape)\n",
    "print('y_train shape :', y_train.shape)\n",
    "print('X_test shape :', X_test.shape)\n",
    "print('y_test shape :', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scale and flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale data\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "# Reshape data\n",
    "X_train = X_train.reshape((-1, 32*32*3))\n",
    "X_test = X_test.reshape((-1, 32*32*3))\n",
    "# Reshape labels to shape of (n_samples, )\n",
    "y_train = y_train.reshape(y_train.size, )\n",
    "y_test = y_test.reshape(y_test.size, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('X_train shape :', X_train.shape)\n",
    "print('y_train shape :', y_train.shape)\n",
    "print('X_test shape :', X_test.shape)\n",
    "print('y_test shape :', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2./b. Fit SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_losses = ['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron']\n",
    "saved_models = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DEFINE SGD-CLASSIFIER\n",
    "#\n",
    "# 1. ABOUT LOSS:\n",
    "# The documentation say the following abot (classification) losses:\n",
    "# > [...]\n",
    "# > The possible options are 'hinge', 'log', 'modified_huber',\n",
    "# > 'squared_hinge', 'perceptron' [...]\n",
    "#\n",
    "# > The 'log' loss gives logistic regression, a probabilistic classifier.\n",
    "# > 'modified_huber' is another smooth loss that brings tolerance to\n",
    "# > outliers as well as probability estimates.\n",
    "# > 'squared_hinge' is like hinge but is quadratically penalized.\n",
    "# > 'perceptron' is the linear loss used by the perceptron algorithm.\n",
    "# > [...]\n",
    "loss = _losses[4]\n",
    "penalty = 'l2'\n",
    "model_ex2 = SGDClassifier(loss=loss,\n",
    "                          penalty=penalty,\n",
    "                          alpha=0.0001,\n",
    "                          l1_ratio=0.15,\n",
    "                          fit_intercept=True,\n",
    "                          max_iter=10000,\n",
    "                          tol=0.001,\n",
    "                          shuffle=True,\n",
    "                          epsilon=0.1,\n",
    "                          n_jobs=-1,\n",
    "                          random_state=42,\n",
    "                          learning_rate='optimal',\n",
    "                          validation_fraction=0.2,\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Fit model\n",
    "model_ex2.fit(X_train, y_train)\n",
    "saved_models[loss] = model_ex2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pickling\n",
    "- Save models if all of them were fitted\n",
    "- Load models if there is a saved instance of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_file = './models/saved_models_ex2'\n",
    "if len(saved_models) == len(_losses):\n",
    "    with open(pickle_file, 'wb') as f:\n",
    "        pickle.dump(saved_models, f)\n",
    "if os.path.exists(pickle_file):\n",
    "    with open(pickle_file, 'rb') as f:\n",
    "        saved_models = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2./c. Make predictions with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load specific model\n",
    "loss = _losses[0]\n",
    "model = saved_models[loss]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and accuracy metric and the confusion matrix\n",
    "accuracy = accuracy_metric(y_test=y_test, y_pred=y_pred)\n",
    "conf_mat = confusion_matrix(y_test, y_pred, labels=[i for i in range(0,10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(conf_mat, y_test, labels=[i for i in range(0,10)],\n",
    "                      title=('Fig. 4. Confusion matrix of the predictions on the CIFAR10 dataset using\\n' +\n",
    "                             'the SGDClassifier model with `{0}` loss and `{1}` penalty.\\n'.format(loss, penalty) +\n",
    "                             'Accuracy of model is {0:.3f}%'.format(accuracy)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10*3,10*2),\n",
    "           facecolor='black')\n",
    "gs = gridspec.GridSpec(2, 6)\n",
    "gs.update(hspace=0.2, wspace=0.2)\n",
    "\n",
    "ax1 = plt.subplot(gs[0, :2])\n",
    "ax2 = plt.subplot(gs[0, 2:4])\n",
    "ax3 = plt.subplot(gs[0, 4:6])\n",
    "ax4 = plt.subplot(gs[1, 1:3])\n",
    "ax5 = plt.subplot(gs[1, 3:5])\n",
    "axes = [ax1, ax2, ax3, ax4, ax5]\n",
    "\n",
    "for i, ax in enumerate(axes):\n",
    "    ax.set_facecolor('black')\n",
    "    ax.plot([0, 1], [0, 1], color=rocket_cmap(0.25), lw=5, linestyle='--')\n",
    "\n",
    "    # Current model\n",
    "    model = saved_models[_losses[i]]\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_metric(y_test=y_test, y_pred=y_pred)\n",
    "    \n",
    "    # Calculate ROC and AUC\n",
    "    fpr_tr, tpr_tr, roc_auc_tr = compute_roc(model, X_train, y_train)\n",
    "    fpr_ts, tpr_ts, roc_auc_ts = compute_roc(model, X_test, y_test)\n",
    "    \n",
    "    # My model\n",
    "    ax.plot(fpr_tr, tpr_tr,\n",
    "            label='ROC curve [train] \\n(AUC = %0.3f)' % roc_auc_tr,\n",
    "            color=cm.magma(0.75), lw=4, alpha=0.8)\n",
    "    ax.plot(fpr_ts, tpr_ts,\n",
    "            label='ROC curve [test] \\n(AUC = %0.3f)' % roc_auc_ts,\n",
    "            color=cm.magma(0.93), lw=4, alpha=0.8)\n",
    "\n",
    "    ax.set_xlim([-0.02, 1.02])\n",
    "    ax.set_ylim([-0.02, 1.02])\n",
    "\n",
    "    ax.set_title('Loss used : `{}`\\n'.format(_losses[i]) +\n",
    "                 'Accuracy : {:.3f}%'.format(accuracy),\n",
    "                 fontsize=axistitlesize, fontweight='bold', color='white')\n",
    "    ax.set_xlabel('False Positive Rate', fontsize=axislabelsize, fontweight='bold', color='white')\n",
    "    ax.set_ylabel('True Positive Rate', fontsize=axislabelsize, fontweight='bold', color='white')\n",
    "    ax.tick_params(axis='both', which='major', labelsize=axisticksize, colors='white')\n",
    "\n",
    "    ax.legend(loc='lower right', fontsize=axislegendsize-4)\n",
    "\n",
    "plt.suptitle('Fig. 5. ROC curve of the SGDClassifier model, on the CIFAR10 dataset with different losses.',\n",
    "             fontsize=axistitlesize+5, y=0.08, color='white')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems, that the best choice of loss for the `SGDClassifier` is its default, `hingle` loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train a RandomForest classifier\n",
    "\n",
    "* Plot the ROC curve with AUC scores on the test set.\n",
    "* Calculate accuracy of the classifier on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3./a. Load and preprocess the CIFAR10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CIFAR 10 dataset\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('X_train shape :', X_train.shape)\n",
    "print('y_train shape :', y_train.shape)\n",
    "print('X_test shape :', X_test.shape)\n",
    "print('y_test shape :', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scale and flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale data\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "# Reshape data\n",
    "X_train = X_train.reshape((-1, 32*32*3))\n",
    "X_test = X_test.reshape((-1, 32*32*3))\n",
    "# Reshape labels to shape of (n_samples, )\n",
    "y_train = y_train.reshape(y_train.size, )\n",
    "y_test = y_test.reshape(y_test.size, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('X_train shape :', X_train.shape)\n",
    "print('y_train shape :', y_train.shape)\n",
    "print('X_test shape :', X_test.shape)\n",
    "print('y_test shape :', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3./b. Fit RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DEFINE RANDOM-FOREST-CLASSIFIER\n",
    "model_ex3 = RandomForestClassifier(n_estimators=100,\n",
    "                                   criterion='gini',\n",
    "                                   max_depth=30,\n",
    "                                   min_samples_split=2,\n",
    "                                   min_samples_leaf=1,\n",
    "                                   min_weight_fraction_leaf=0.0,\n",
    "                                   max_features='auto',\n",
    "                                   max_leaf_nodes=None,\n",
    "                                   min_impurity_decrease=0.0,\n",
    "                                   min_impurity_split=None,\n",
    "                                   bootstrap=True,\n",
    "                                   oob_score=False,\n",
    "                                   n_jobs=-1,\n",
    "                                   random_state=42,\n",
    "                                   verbose=0,\n",
    "                                   warm_start=False,\n",
    "                                   class_weight=None,\n",
    "                                   ccp_alpha=0.0,\n",
    "                                   max_samples=None\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model_ex3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_file = './models/saved_models_ex3'\n",
    "with open(pickle_file, 'wb') as f:\n",
    "    pickle.dump(model_ex3, f)\n",
    "if os.path.exists(pickle_file):\n",
    "    with open(pickle_file, 'rb') as f:\n",
    "        model_ex3 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3./c. Make predictions with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_ex3.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and accuracy metric and the confusion matrix\n",
    "accuracy = accuracy_metric(y_test=y_test, y_pred=y_pred)\n",
    "conf_mat = confusion_matrix(y_test, y_pred, labels=[i for i in range(0,10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(conf_mat, y_test, labels=[i for i in range(0,10)],\n",
    "                      title=('Fig. 6. Confusion matrix of the predictions\\n' +\n",
    "                             'on the CIFAR10 dataset using the RandomForestClassifier model.\\n' +\n",
    "                             'Accuracy of model is {0:.3f}%'.format(accuracy)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_tr, tpr_tr, roc_auc_tr = compute_roc(model_ex3, X_train, y_train)\n",
    "fpr_ts, tpr_ts, roc_auc_ts = compute_roc(model_ex3, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize=(11, 11),\n",
    "                         facecolor='black', subplot_kw={'facecolor' : 'black'})\n",
    "\n",
    "axes.plot([0, 1], [0, 1], color=rocket_cmap(0.25), lw=5, linestyle='--')\n",
    "\n",
    "# My model\n",
    "axes.plot(fpr_tr, tpr_tr,\n",
    "          label='ROC curve [train] \\n(AUC = %0.3f)' % roc_auc_tr,\n",
    "          color=cm.magma(0.75), lw=4, alpha=0.8)\n",
    "axes.plot(fpr_ts, tpr_ts,\n",
    "          label='ROC curve [test] \\n(AUC = %0.3f)' % roc_auc_ts,\n",
    "          color=cm.magma(0.93), lw=4, alpha=0.8)\n",
    "\n",
    "axes.set_xlim([-0.02, 1.02])\n",
    "axes.set_ylim([-0.02, 1.02])\n",
    "\n",
    "axes.set_xlabel('False Positive Rate', fontsize=axislabelsize, fontweight='bold', color='white')\n",
    "axes.set_ylabel('True Positive Rate', fontsize=axislabelsize, fontweight='bold', color='white')\n",
    "axes.tick_params(axis='both', which='major', labelsize=axisticksize, colors='white')\n",
    "\n",
    "axes.legend(loc='lower right', fontsize=axislegendsize)\n",
    "\n",
    "plt.suptitle('Fig. 7. ROC curve of the RandomForestClassifier model,\\n' +\n",
    "             'on the CIFAR10 dataset.',\n",
    "             fontsize=axistitlesize+5, y=0.04, color='white')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train an multi layer perceptron classifier\n",
    "\n",
    "* use the `MLPClassifier` from `sklearn`\n",
    "* Set its parameter to `max_iter = 30` or if you have time, set it for at least `100`. After `30` iterations the model does not converge but gives reasonable predictions (with default parameters).\n",
    "* Plot the ROC curves with AUC scores for the test set.\n",
    "* Calculate the accuracy of the model on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4./a. Load and preprocess the CIFAR10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CIFAR 10 dataset\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('X_train shape :', X_train.shape)\n",
    "print('y_train shape :', y_train.shape)\n",
    "print('X_test shape :', X_test.shape)\n",
    "print('y_test shape :', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scale and flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale data\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "# Reshape data\n",
    "X_train = X_train.reshape((-1, 32*32*3))\n",
    "X_test = X_test.reshape((-1, 32*32*3))\n",
    "# Reshape labels to shape of (n_samples, )\n",
    "y_train = y_train.reshape(y_train.size, )\n",
    "y_test = y_test.reshape(y_test.size, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('X_train shape :', X_train.shape)\n",
    "print('y_train shape :', y_train.shape)\n",
    "print('X_test shape :', X_test.shape)\n",
    "print('y_test shape :', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4./b. Fit MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DEFINE MLP-CLASSIFIER\n",
    "# - max_iter set to its default : 200\n",
    "model_ex4 = MLPClassifier(hidden_layer_sizes=(100,),\n",
    "                          activation='relu',\n",
    "                          solver='adam',\n",
    "                          alpha=0.0001,\n",
    "                          batch_size='auto',\n",
    "                          learning_rate='constant',\n",
    "                          learning_rate_init=0.001,\n",
    "                          power_t=0.5,\n",
    "                          max_iter=200,\n",
    "                          shuffle=True,\n",
    "                          random_state=42,\n",
    "                          tol=0.0001,\n",
    "                          verbose=False,\n",
    "                          warm_start=False,\n",
    "                          momentum=0.9,\n",
    "                          nesterovs_momentum=True,\n",
    "                          early_stopping=False,\n",
    "                          validation_fraction=0.1,\n",
    "                          beta_1=0.9,\n",
    "                          beta_2=0.999,\n",
    "                          epsilon=1e-08,\n",
    "                          n_iter_no_change=10,\n",
    "                          max_fun=15000\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Only run if necessary\n",
    "# My runtime was: 1h 23min 45s\n",
    "#model_ex4.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_file = './models/saved_models_ex4'\n",
    "#with open(pickle_file, 'wb') as f:\n",
    "#    pickle.dump(model_ex4, f)\n",
    "if os.path.exists(pickle_file):\n",
    "    with open(pickle_file, 'rb') as f:\n",
    "        model_ex4 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4./c. Make predictions with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_ex4.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and accuracy metric and the confusion matrix\n",
    "accuracy = accuracy_metric(y_test=y_test, y_pred=y_pred)\n",
    "conf_mat = confusion_matrix(y_test, y_pred, labels=[i for i in range(0,10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(conf_mat, y_test, labels=[i for i in range(0,10)],\n",
    "                      title=('Fig. 8. Confusion matrix of the predictions\\n' +\n",
    "                             'on the CIFAR10 dataset using the MLPClassifier model.\\n' +\n",
    "                             'Accuracy of model is {0:.3f}%'.format(accuracy)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_tr, tpr_tr, roc_auc_tr = compute_roc(model_ex4, X_train, y_train)\n",
    "fpr_ts, tpr_ts, roc_auc_ts = compute_roc(model_ex4, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize=(11, 11),\n",
    "                         facecolor='black', subplot_kw={'facecolor' : 'black'})\n",
    "\n",
    "axes.plot([0, 1], [0, 1], color=rocket_cmap(0.25), lw=5, linestyle='--')\n",
    "\n",
    "# My model\n",
    "axes.plot(fpr_tr, tpr_tr,\n",
    "          label='ROC curve [train] \\n(AUC = %0.3f)' % roc_auc_tr,\n",
    "          color=cm.magma(0.75), lw=4, alpha=0.8)\n",
    "axes.plot(fpr_ts, tpr_ts,\n",
    "          label='ROC curve [test] \\n(AUC = %0.3f)' % roc_auc_ts,\n",
    "          color=cm.magma(0.93), lw=4, alpha=0.8)\n",
    "\n",
    "axes.set_xlim([-0.02, 1.02])\n",
    "axes.set_ylim([-0.02, 1.02])\n",
    "\n",
    "axes.set_xlabel('False Positive Rate', fontsize=axislabelsize, fontweight='bold', color='white')\n",
    "axes.set_ylabel('True Positive Rate', fontsize=axislabelsize, fontweight='bold', color='white')\n",
    "axes.tick_params(axis='both', which='major', labelsize=axisticksize, colors='white')\n",
    "\n",
    "axes.legend(loc='lower right', fontsize=axislegendsize)\n",
    "\n",
    "plt.suptitle('Fig. 9. ROC curve of the MLPClassifier model,\\n' +\n",
    "             'on the CIFAR10 dataset.',\n",
    "             fontsize=axistitlesize+5, y=0.04, color='white')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train a ResNet50 CNN model on the dataset, utilize ImageNet pre-trained weights and fine-tune for at least 3 epochs:\n",
    "\n",
    "* training for 3 epochs should be enough to prove that this model is superior compared to others, train longer to explore the possibilities of the model\n",
    "\n",
    "Convert the dataset:\n",
    "\n",
    "```python\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(32)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "test_dataset = test_dataset.batch(32)\n",
    "```\n",
    "\n",
    "Hints:\n",
    "\n",
    "* loading a pretrained model and letting its parameters be tunable\n",
    "\n",
    "```python\n",
    "backbone = tf.keras.applications.YOUR_MODEL_OF_CHOICE # set include_top = False to get rid of the dense layers\n",
    "backbone.trainable = True # set if you want to fine-tune the pretrained weights too, otherwise set to False\n",
    "```\n",
    "\n",
    "* defining your custom model with the pretrained backbone\n",
    "\n",
    "```python\n",
    "# YOUR_MODEL_OF_CHOICE here is ResNet50 as per the task description.\n",
    "\n",
    "# Functional TensorFlow API\n",
    "def my_own_model():\n",
    "  inp = tf.keras.layers.Input(shape=(32, 32, 3))\n",
    "  x = tf.keras.applications.YOUR_MODEL_OF_CHOICE.preprocess_input(inp)\n",
    "\n",
    "  x = backbone(x)\n",
    "  # Here comes some more layers\n",
    "  # and flattening where needed!\n",
    "  out = # layer outputting the specified number of classes\n",
    "        # with or without a softmax activation, later on\n",
    "        # the choice of the loss depends on this\n",
    "  model = tf.keras.models.Model(inputs=inp, outputs=out)\n",
    "  return model\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5./a. Load and preprocess dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CIFAR 10 dataset\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('X_train shape :', X_train.shape)\n",
    "print('y_train shape :', y_train.shape)\n",
    "print('X_test shape :', X_test.shape)\n",
    "print('y_test shape :', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale data\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "# Reshape data\n",
    "X_train = X_train.reshape((-1, 32,32, 3))\n",
    "X_test = X_test.reshape((-1, 32,32, 3))\n",
    "# Convert labels to one-hot encoded arrays\n",
    "y_train = label_binarize(y_train, classes=np.unique(y_train)).reshape(-1, 1, 1, 10)\n",
    "y_test = label_binarize(y_test, classes=np.unique(y_test)).reshape(-1, 1, 1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('X limits :', X_train.min(), '-', X_train.max())\n",
    "print('X_train shape :', X_train.shape)\n",
    "print('y_train shape :', y_train.shape)\n",
    "print('X_test shape :', X_test.shape)\n",
    "print('y_test shape :', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5./b. Train custom model for 3 epochs long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.models as km\n",
    "import tensorflow.keras.layers as kl\n",
    "import tensorflow.keras.regularizers as kr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_model(imsize, n_channels=1, n_class=10,\n",
    "               model_name='default_model'):\n",
    "    \"\"\"\n",
    "    Creating a model based on the advice of task 5 in homework 11.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    imsize : int\n",
    "        Side length of the square-shaped input image in pixels.\n",
    "    n_channels : int\n",
    "        Number of color/other channels of the input images.\n",
    "    n_class : int\n",
    "        Number of classes in the classification problem.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    model : tensorflow.python.keras.engine.training.Model\n",
    "        The constructed, yet unconfigured CNN model.\n",
    "    \"\"\"\n",
    "    # Tensorflow placeholder for inputs\n",
    "    inp = kl.Input(shape=(imsize, imsize, n_channels),\n",
    "                   name='input_ex5')\n",
    "\n",
    "    # Define a model for the backbone of the net\n",
    "    # Here it's ResNet50 with loaded ImageNet weights\n",
    "    model = tf.keras.applications.ResNet50(include_top=False,\n",
    "                                           input_tensor=inp, weights='imagenet')\n",
    "    model.trainable = True\n",
    "    \n",
    "    # Preprocess the input first\n",
    "    x = tf.keras.applications.resnet50.preprocess_input(inp)\n",
    "    \n",
    "    # Run through the backbone the preprocessed input\n",
    "    x = model(inp)\n",
    "    \n",
    "    # Final flatten FC\n",
    "    out = kl.Dense(units=n_class,\n",
    "                   activation='softmax',\n",
    "                   name='final_dense_ex5')(x)\n",
    "\n",
    "    # Define model\n",
    "    model = km.Model(inputs=inp, outputs=out,\n",
    "                     name=model_name)\n",
    "\n",
    "    # Multi GPU model\n",
    "    #if(len(gpu.split(',')) > 1):\n",
    "    #    model = multi_gpu_model(model, gpus=len(gpu.split(',')))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/device:GPU:0'):\n",
    "    # Create checkpoint file to save best model into\n",
    "    okay_model_ex5 = kc.ModelCheckpoint('./models/okay_model_ex5.hdf5', save_best_only=True, verbose=1)\n",
    "    # Configure early stopping with N epochs of patience\n",
    "    es_ex5 = kc.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
    "    \n",
    "    # Define the model\n",
    "    model_ex5 = best_model(imsize=32, n_channels=3, n_class=10,\n",
    "                           model_name='model_ex5')\n",
    "    \n",
    "    # Configure the model\n",
    "    model_ex5.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.004),\n",
    "                      loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0),\n",
    "                      metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ex5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_ex5 = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/device:GPU:0'):\n",
    "    history_ex5 = model_ex5.fit(x=X_train,\n",
    "                                y=y_train,\n",
    "                                batch_size=32,\n",
    "                                epochs=epochs_ex5,\n",
    "                                verbose=1,\n",
    "                                validation_split=0.2,\n",
    "                                shuffle=True,\n",
    "                                callbacks=[es_ex5, okay_model_ex5],\n",
    "                                initial_epoch=0,\n",
    "                                steps_per_epoch=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5./c. Make predictions with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_ex5.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert one-hot encoded preds and tests to normal arrays\n",
    "y_test_b = y_test.reshape(-1, 10)\n",
    "y_pred_b = y_pred.reshape(-1, 10)\n",
    "y_test_b = y_test_b.argmax(axis=-1)\n",
    "y_pred_b = y_pred_b.argmax(axis=-1)\n",
    "\n",
    "# Calculate and accuracy metric and the confusion matrix\n",
    "accuracy = accuracy_metric(y_test=y_test_b, y_pred=y_pred_b)\n",
    "conf_mat = confusion_matrix(y_test_b, y_pred_b, labels=[i for i in range(0,10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(conf_mat, y_test_b, labels=[i for i in range(0,10)],\n",
    "                      title=('Fig. 10. Confusion matrix of the predictions\\n' +\n",
    "                             'on the test set using ResNet50 with pre-trained weights.\\n' +\n",
    "                             'Accuracy of model is {0:.3f}%'.format(accuracy)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5./d. Train it longer (eg. 100 epochs)\n",
    "\n",
    "- I also utilized early stopping with 20 epochs patience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/device:GPU:0'):\n",
    "    # Create checkpoint file to save best model into\n",
    "    best_model_ex5 = kc.ModelCheckpoint('./models/best_model_ex5.hdf5', save_best_only=True, verbose=1)\n",
    "    # Configure early stopping with N epochs of patience\n",
    "    es_ex5 = kc.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20)\n",
    "    \n",
    "    # Define the model\n",
    "    model_ex5 = best_model(imsize=32, n_channels=3, n_class=10,\n",
    "                           model_name='model_ex5')\n",
    "    \n",
    "    # Configure the model\n",
    "    model_ex5.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.003),\n",
    "                      loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0),\n",
    "                      metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ex5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_ex5 = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/device:GPU:0'):\n",
    "    history_ex5 = model_ex5.fit(x=X_train,\n",
    "                                y=y_train,\n",
    "                                batch_size=32,\n",
    "                                epochs=epochs_ex5,\n",
    "                                verbose=1,\n",
    "                                validation_split=0.2,\n",
    "                                shuffle=True,\n",
    "                                callbacks=[es_ex5, best_model_ex5],\n",
    "                                initial_epoch=0,\n",
    "                                steps_per_epoch=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5./e. Evaluate loss and accuracy history of longer run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = 1\n",
    "ncols = 2\n",
    "fig, axes = plt.subplots(nrows, ncols, figsize=(ncols*12, nrows*8),\n",
    "                         facecolor='black', subplot_kw={'facecolor' : 'black'})\n",
    "\n",
    "# LOSS GRAPH\n",
    "ax = axes[0]\n",
    "ax.plot(history_ex5.epoch, history_ex5.history['loss'], label='Training loss',\n",
    "        c=cm.magma(0.75), lw=5)\n",
    "ax.plot(history_ex5.epoch, history_ex5.history['val_loss'], label='Validation loss',\n",
    "        c=cm.magma(0.93), lw=5)\n",
    "ax.set_ylabel('Loss', fontsize=axislabelsize, fontweight='bold',\n",
    "              color='white')\n",
    "\n",
    "# ACCURACY GRAPH\n",
    "ax = axes[1]\n",
    "ax.plot(history_ex5.epoch, history_ex5.history['accuracy'], label='Training accuracy',\n",
    "        c=cm.magma(0.75), lw=5)\n",
    "ax.plot(history_ex5.epoch, history_ex5.history['val_accuracy'], label='Validation accuracy',\n",
    "        c=cm.magma(0.93), lw=5)\n",
    "ax.set_ylabel('Accuracy', fontsize=axislabelsize, fontweight='bold',\n",
    "              color='white')\n",
    "\n",
    "for ax in axes.reshape(-1):\n",
    "    if epochs_ex5 > history_ex5.epoch[-1] : ax.axvline(x=history_ex5.epoch[-1], label='Early stopping',\n",
    "                                                       color=cm.magma(0.5), ls='--', lw=4)\n",
    "    ax.set_xlabel('Epochs', fontsize=axislabelsize, fontweight='bold',\n",
    "                  color='white')\n",
    "    #ax.xaxis.set_major_locator(plticker.MultipleLocator(base=1.0))\n",
    "    ax.tick_params(axis='both', which='major', labelsize=axisticksize,\n",
    "                   colors='white')\n",
    "\n",
    "axes[0].legend(loc='upper right', fontsize=axislegendsize)\n",
    "axes[1].legend(loc='lower right', fontsize=axislegendsize)\n",
    "\n",
    "plt.suptitle('Fig. 11. The loss and accuracy history of the ResNet50 model trained on the CIFAR10 dataset. The loss history can be\\n' +\n",
    "             'seen on the left side, while the training accuracy on the right.',\n",
    "             color='white',\n",
    "             fontsize=axistitlesize+5, y=-0.02)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5./f. Make predictions with the more trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_ex5.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert one-hot encoded preds and tests to normal arrays\n",
    "y_test_b = y_test.reshape(-1, 10)\n",
    "y_pred_b = y_pred.reshape(-1, 10)\n",
    "y_test_b = y_test_b.argmax(axis=-1)\n",
    "y_pred_b = y_pred_b.argmax(axis=-1)\n",
    "\n",
    "# Calculate and accuracy metric and the confusion matrix\n",
    "accuracy = accuracy_metric(y_test=y_test_b, y_pred=y_pred_b)\n",
    "conf_mat = confusion_matrix(y_test_b, y_pred_b, labels=[i for i in range(0,10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(conf_mat, y_test_b, labels=[i for i in range(0,10)],\n",
    "                      title=('Fig. 12. Confusion matrix of the predictions on the CIFAR10 dataset\\n' +\n",
    "                             'using ResNet50 with pre-trained weights.\\n' +\n",
    "                             'Accuracy of model is {0:.3f}%'.format(accuracy)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPIfy3OaOXRicxFjAwGWcOU",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "hw11_no_code.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
